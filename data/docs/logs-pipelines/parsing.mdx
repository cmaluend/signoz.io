---
date: 2026-01-04
id: logs-parsing
title: Logs Parsing with Pipelines
description: Complete guide to parsing logs using SigNoz Pipelines including Regex, Grok, and JSON.
doc_type: howto
---

import GetHelp from '@/components/shared/get-help.md'

Log parsing transforms unstructured log messages into structured data, allowing you to filter, aggregate, and analyze your logs efficiently in SigNoz.

## Why Parse Logs?

Consider this raw application log:

```text
2025-12-27 10:00:00 [ERROR] User 456 failed login from 10.0.0.5 - invalid password
```

Without parsing, you can only search the full text. You cannot filter by log level, count errors per user, or identify suspicious IPs.

After parsing, the log becomes structured:

```json
{
  "body": "2025-12-27 10:00:00 [ERROR] User 456 failed login from 10.0.0.5 - invalid password",
  "attributes": {
    "level": "ERROR",
    "user_id": "456",
    "ip": "10.0.0.5",
    "reason": "invalid password"
  }
}
```

With structured attributes, you can:

- **Filter** logs by `level = ERROR` or `user_id = 456`
- **Aggregate** failed logins by IP address to detect brute-force attempts
- **Build dashboards** showing error rates over time
- **Create alerts** when a specific user exceeds failed login thresholds

## Prerequisites

- You are sending logs to SigNoz.
- You have access to the **Logs Pipelines** section in SigNoz UI.

Learn more about SigNoz [Logs Pipelines](https://signoz.io/docs/logs-pipelines/introduction/).

## Creating a Pipeline

Before you can parse logs, you need to create a pipeline that will filter and process them.

### Step 1: Navigate to Pipelines Page

In SigNoz, go to **Logs** → **Pipelines**

<Figure
  src="/img/docs/logs-management/logs-pipelines/logs-parsing-pipeline-step1.webp"
  alt="Navigate to Log Pipelines"
  caption="Navigate to Log Pipelines"
/>

### Step 2: Create a New Pipeline

- If you do not have existing pipelines, press the **"New Pipeline"** button.

  <Figure
    src="/img/docs/logs-management/logs-pipelines/logs-parsing-pipeline-step2.webp"
    alt="New Pipeline Button"
    caption="New Pipeline Button"
  />

- If you already have some pipelines, press the **"Enter Edit Mode"** button and then click the **"Add a New Pipeline"** button at the bottom of the list.

<Figure
  src="/img/docs/logs-management/logs-pipelines/logs-parsing-pipeline-step3.webp"
  alt="Enter Edit Mode button"
  caption="Enter Edit Mode button"
/>

<Figure
  src="/img/docs/logs-management/logs-pipelines/logs-parsing-pipeline-step4.webp"
  alt="Add a New Pipeline button"
  caption="Add a New Pipeline button"
/>

### Step 3: Configure the Pipeline

Provide details about the pipeline in the Create Pipeline Dialog:

- **Name:** Provide a descriptive pipeline name.
- **Description:** Add a detailed description for your pipeline (optional).
- **Filter:** Use the filter field to select the logs you want to process. For example, `service.name = my-app` or `log.file.name = app.log`.
- **Filtered Logs Preview:** Verify that the logs you want to process are selected.

<Figure
  src="/img/docs/logs-management/logs-pipelines/logs-parsing-pipeline-step5.webp"
  alt="Create New Pipeline dialog"
  caption="Create New Pipeline dialog"
/>

Press the **"Create"** button to create the pipeline.

## Choosing the Right Parser

SigNoz offers several processors to handle different types of logs. Choosing the right one depends on your log format.

### JSON Parser

If your logs are formatted as JSON strings, use the **JSON Parser**. It automatically expands the JSON structure into log attributes.

**Best for**: Structured logs generated by modern applications.

[**Read the JSON Parsing Guide**](https://signoz.io/docs/logs-pipelines/guides/json/)

### Regex Parser

If your logs are unstructured text with a predictable pattern, use the **Regex Parser**. It allows you to define flexible named capture groups using regular expressions.

**Best for**: Custom or legacy application logs.

[**Read the Regex Parsing Guide**](https://signoz.io/docs/logs-pipelines/guides/regex-parser/)

### Grok Parser

If your logs follow common standard formats (like Apache, Nginx, or Syslog), use the **Grok Parser**. It provides pre-defined patterns that are easier to use and maintain than raw regex.

**Best for**: Web server access logs, system logs, and standard middleware logs.

[**Read the Grok Parsing Guide**](https://signoz.io/docs/logs-pipelines/guides/grok-parser/)

### Specialized Parsers

- **[Trace Parser](https://signoz.io/docs/logs-pipelines/guides/trace/)**: Extract trace IDs from log messages and map them to the official trace ID field.
- **[Timestamp Parser](https://signoz.io/docs/logs-pipelines/guides/timestamp-parsing/)**: Extract timestamps from log messages and map them to the official timestamp field.
- **[Severity Parser](https://signoz.io/docs/logs-pipelines/guides/severity-parsing/)**: Map log levels (INFO, ERROR, etc.) to the OpenTelemetry severity number.
- **[Add Parser](https://signoz.io/docs/logs-pipelines/processors/#add)**: Add a new attribute to the log.
- **[Remove Parser](https://signoz.io/docs/logs-pipelines/processors/#remove)**: Remove an attribute from the log.
- **[Move Parser](https://signoz.io/docs/logs-pipelines/processors/#move)**: Move an attribute to a new location in the log.
- **[Copy Parser](https://signoz.io/docs/logs-pipelines/processors/#copy)**: Copy an attribute to a new location in the log.

<details>
<ToggleHeading>

## Troubleshooting

</ToggleHeading>

### Error: "could not simulate log pipelines processing"

Your pattern must include at least one named capture group:

- Regex: `(?P<name>pattern)`
- Grok: `%{PATTERN_NAME:capture_name}`

Test patterns using <a href="https://regex101.com/" target="_blank" rel="noopener noreferrer nofollow">regex101</a> (Go flavor) or <a href="https://grokdebugger.com/" target="_blank" rel="noopener noreferrer nofollow">Grok Debugger</a>.

### Pipeline not processing logs

Check deployment status in **Logs** → **Pipelines** → **Change History** tab. If status shows "Failed", review the error and fix. If "In Progress", wait for completion.

### Filter not matching logs

Verify the filter expression matches your log attributes. Check available attributes by expanding a log in **Logs Explorer**. Use `=` for exact match or `contains` for partial match.

</details>

## Get Help

<GetHelp />

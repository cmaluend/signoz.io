---
date: 2024-06-06
id: traces

title: View Traces in SigNoz
description: Learn how to use distributed tracing in SigNoz to monitor application performance. Visualize, filter, and inspect traces to gain detailed insights into your applications.
---

import GetHelp from '@/components/shared/get-help.md'
import PrereqsInstrument from '@/components/shared/prereqs-instrument.md'
import UseHotRod from '@/components/shared/use-hotrod.md'

This page shows how you can use distributed tracing to retrieve detailed telemetry data and see how your applications are performing. This section explains:

- How to visualize aggregate metrics from traces
- How to filter your spans
- How to inspect a span

## Prerequisites

<PrereqsInstrument />

## Open the Traces Section

From the sidebar, select **Traces**:

<figure data-zoomable align='center'>
    <img src="/img/traces-explorer-v0.53.0.png" alt="Traces Explorer"/>
    <figcaption><i> Traces Explorer </i></figcaption>
</figure>

## Visualize Aggregate Metrics from Traces

SigNoz allows you to create aggregates of your filtered traces with various aggregate functions. Refer to query builder aggregation docs [here](https://signoz.io/docs/userguide/query-builder/#aggregation)

## Filter Spans by Tags/Attributes

The Traces Explorer in SigNoz provides a feature for quick filtering of spans using various parameters. This functionality allows users to quickly search their specific spans, making it easier to analyze and debug applications.

There are two ways in which you can filter traces by tags:

- You can select a filter from the **Quick Filter**. More details on available quick filters are [here](/docs/product-features/trace-explorer/#quick-filters)
<figure data-zoomable align='center'>
    <img src="/img/docs/product-features/trace-explorer/trace-explorer-quick-filters.webp" alt="Quick Filters in Traces Explorer"/>
    <figcaption><i> Quick Filters in Traces Explorer </i></figcaption>
</figure>
- You can use the query builder. To access the query builder, select the **Search Filter** input. Then, use the dropdown list to select a key from the list of your attributes, select an operator and enter a value. When youâ€™ve finished, select the **Stage and Run Query** button. Refer to [this doc](/docs/userguide/query-builder/#using-the-filtering-feature) for more details on Query Builder.


## Inspect a Span

To further troubleshoot your application, you can select a span from the list to view its details. For details, see the [Span Details](/docs/userguide/span-details) page.

## Missing Spans

If you are seeing missing spans in your traces, it could be due to the following reasons:

- One of the service is instrumented but not sending spans to SigNoz. For example, the service might not be exporting spans to SigNoz.

- The spans are not being sent to SigNoz. For example, the spans might be dropped due to network issues or the spans might be dropped due to sampling.

## Span Gaps

Sometimes it's possible that there are gaps between consequent spans. This happens when some process/code are not traced. For Example, by default OpenTelemetry auto instrumentation libraries do not trace the custom functions/methods. This can be fixed by adding manual instrumentation to the code.

Example of span gaps:
![Span Gap](/img/docs/span-gap.png)

## Understanding Trace Duration Discrepancies

When analyzing latency metrics in the traces list, you may notice that the duration shown differs from what appears in the trace details. This is because:

**The duration column in the traces list shows the duration of the root span, not the entire trace duration.**

This can lead to apparent discrepancies for several reasons:

- **The root span may complete before all child spans finish** - The root operation might return a response while background tasks continue processing
- **Asynchronous operations** - Child spans can run longer than the root span when operations are performed asynchronously
- **Total trace duration** - The trace details view shows the complete duration including all spans, which may be longer than just the root span

### Example Scenario

You might see a trace listed as **38.9 seconds** in the traces page, but when you open the trace details, it shows a total duration of **1 minute**. This happens when:

1. The root span (the initial request handler) completed in 38.9 seconds
2. Other spans in the trace (such as background jobs, async tasks, or queued operations) continued running
3. The total time from the first span start to the last span end was 1 minute

This behavior is expected and reflects how distributed systems actually work. If you need to measure specific service-to-service latencies rather than root span duration, see the [writing ClickHouse queries documentation](/docs/userguide/writing-clickhouse-traces-query/#querying-for-specific-service-latencies) for guidance on using `kind_string = 'Client'` filters.

## Get Help

<GetHelp />

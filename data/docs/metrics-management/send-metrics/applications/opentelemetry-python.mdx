---
date: 2026-01-17
id: opentelemetry-python
title: Send Metrics from Python application
description: Learn how to instrument your Python application with OpenTelemetry to send metrics to SigNoz

doc_type: howto
---

This guide shows you how to instrument your Python application with OpenTelemetry to send metrics to SigNoz. You will learn how to collect system and runtime metrics, use auto-instrumentation, and create custom metrics.

<KeyPointCallout title="Using self-hosted SigNoz?" defaultCollapsed={true}>
    Most steps are identical. To adapt this guide, update the endpoint and remove the ingestion key header as shown in [Cloud → Self-Hosted](https://signoz.io/docs/ingestion/cloud-vs-self-hosted/#cloud-to-self-hosted).
</KeyPointCallout>

## Prerequisites

- Python 3.9 or later
- A SigNoz Cloud account or self-hosted SigNoz instance

## Send metrics to SigNoz

<Tabs entityName="deployment">
<TabItem value="vm" label="VM" default>
<KeyPointCallout title="What classifies as VM?" defaultCollapsed={true}>
    A VM is a virtual computer that runs on physical hardware. This includes:
    - **Cloud VMs**: AWS EC2, Google Compute Engine, Azure VMs, DigitalOcean Droplets
    - **On-premise VMs**: VMware, VirtualBox, Hyper-V, KVM
    - **Bare metal servers**: Physical servers running Linux/Unix directly

    Use this section if you're deploying your Python application directly on a server or VM without containerization.
</KeyPointCallout>

### Step 1. Set environment variables
Set the following environment variables to configure the OpenTelemetry exporter:
```bash
export OTEL_EXPORTER_OTLP_METRICS_ENDPOINT="https://ingest.<region>.signoz.cloud:443"
export OTEL_EXPORTER_OTLP_METRICS_HEADERS="signoz-ingestion-key=<your-ingestion-key>"
export OTEL_SERVICE_NAME="<service-name>"
export OTEL_TRACES_EXPORTER="none"
```
Replace the following:
- `<region>`: Your SigNoz Cloud region (`us`, `eu`, or `in`). See [endpoints](https://signoz.io/docs/ingestion/signoz-cloud/overview/#endpoint).
- `<your-ingestion-key>`: Your SigNoz [ingestion key](https://signoz.io/docs/ingestion/signoz-cloud/keys/).
- `<service-name>`: A descriptive name for your service (e.g., `payment-service`).

<KeyPointCallout title="Why explicitly disable traces?" defaultCollapsed={true}>
The bootstrap command (Step 3) installs instrumentations for all detected libraries, including web frameworks like Flask, Django, and FastAPI, as well as database clients and HTTP libraries. These instrumentations generate traces (spans) for every incoming request and outgoing call.

Since `opentelemetry-distro` enables traces by default, these traces would be sent to SigNoz even though this guide only covers metrics. For apps handling many requests, this can generate significant trace volume and costs.

Setting `OTEL_TRACES_EXPORTER="none"` disables traces while keeping metrics working as expected. If you want traces later, see the [Python traces instrumentation guide](https://signoz.io/docs/instrumentation/opentelemetry-python/).
</KeyPointCallout>

</TabItem>

<TabItem value="k8s" label="Kubernetes">
### Step 1. Set environment variables
Add these environment variables to your deployment manifest:
```yaml
env:
- name: OTEL_EXPORTER_OTLP_METRICS_ENDPOINT
  value: 'https://ingest.<region>.signoz.cloud:443'
- name: OTEL_EXPORTER_OTLP_METRICS_HEADERS
  value: 'signoz-ingestion-key=<your-ingestion-key>'
- name: OTEL_SERVICE_NAME
  value: '<service-name>'
- name: OTEL_TRACES_EXPORTER
  value: 'none'
```
Replace the following:
- `<region>`: Your SigNoz Cloud region (`us`, `eu`, or `in`). See [endpoints](https://signoz.io/docs/ingestion/signoz-cloud/overview/#endpoint).
- `<your-ingestion-key>`: Your SigNoz [ingestion key](https://signoz.io/docs/ingestion/signoz-cloud/keys/).
- `<service-name>`: A descriptive name for your service (e.g., `payment-service`).

<KeyPointCallout title="Why explicitly disable traces?" defaultCollapsed={true}>
The bootstrap command (Step 3) installs instrumentations for all detected libraries, including web frameworks like Flask, Django, and FastAPI, as well as database clients and HTTP libraries. These instrumentations generate traces (spans) for every incoming request and outgoing call.

Since `opentelemetry-distro` enables traces by default, these traces would be sent to SigNoz even though this guide only covers metrics. For apps handling many requests, this can generate significant trace volume and costs.

Setting `OTEL_TRACES_EXPORTER: "none"` disables traces while keeping metrics working as expected. If you want traces later, see the [Python traces instrumentation guide](https://signoz.io/docs/instrumentation/opentelemetry-python/).
</KeyPointCallout>
</TabItem>

<TabItem value="windows" label="Windows">
### Step 1. Set environment variables (PowerShell)
```powershell
$env:OTEL_EXPORTER_OTLP_METRICS_ENDPOINT = "https://ingest.<region>.signoz.cloud:443"
$env:OTEL_EXPORTER_OTLP_METRICS_HEADERS = "signoz-ingestion-key=<your-ingestion-key>"
$env:OTEL_SERVICE_NAME = "<service-name>"
$env:OTEL_TRACES_EXPORTER = "none"
```
Replace the following:
- `<region>`: Your SigNoz Cloud region (`us`, `eu`, or `in`).
- `<your-ingestion-key>`: Your SigNoz [ingestion key](https://signoz.io/docs/ingestion/signoz-cloud/keys/).
- `<service-name>`: A descriptive name for your service.

<KeyPointCallout title="Why explicitly disable traces?" defaultCollapsed={true}>
The bootstrap command (Step 3) installs instrumentations for all detected libraries, including web frameworks like Flask, Django, and FastAPI, as well as database clients and HTTP libraries. These instrumentations generate traces (spans) for every incoming request and outgoing call.

Since `opentelemetry-distro` enables traces by default, these traces would be sent to SigNoz even though this guide only covers metrics. For apps handling many requests, this can generate significant trace volume and costs.

Setting `OTEL_TRACES_EXPORTER = "none"` disables traces while keeping metrics working as expected. If you want traces later, see the [Python traces instrumentation guide](https://signoz.io/docs/instrumentation/opentelemetry-python/).
</KeyPointCallout>
</TabItem>

<TabItem value="docker" label="Docker">
### Step 1. Set environment variables in Dockerfile
Add environment variables to your Dockerfile:
```dockerfile:Dockerfile
# ... build stages ...

# Set OpenTelemetry environment variables
ENV OTEL_EXPORTER_OTLP_METRICS_ENDPOINT="https://ingest.<region>.signoz.cloud:443"
ENV OTEL_EXPORTER_OTLP_METRICS_HEADERS="signoz-ingestion-key=<your-ingestion-key>"
ENV OTEL_SERVICE_NAME="<service-name>"
ENV OTEL_TRACES_EXPORTER="none"

CMD ["python", "app.py"]
```

Or pass them at runtime using `docker run`:
```bash
docker run -e OTEL_EXPORTER_OTLP_METRICS_ENDPOINT="https://ingest.<region>.signoz.cloud:443" \
    -e OTEL_EXPORTER_OTLP_METRICS_HEADERS="signoz-ingestion-key=<your-ingestion-key>" \
    -e OTEL_SERVICE_NAME="<service-name>" \
    -e OTEL_TRACES_EXPORTER="none" \
    your-image:latest
```

Replace the following:
- `<region>`: Your SigNoz Cloud region (`us`, `eu`, or `in`). See [endpoints](https://signoz.io/docs/ingestion/signoz-cloud/overview/#endpoint).
- `<your-ingestion-key>`: Your SigNoz [ingestion key](https://signoz.io/docs/ingestion/signoz-cloud/keys/).
- `<service-name>`: A descriptive name for your service (e.g., `payment-service`).

<KeyPointCallout title="Why explicitly disable traces?" defaultCollapsed={true}>
The bootstrap command (Step 3) installs instrumentations for all detected libraries, including web frameworks like Flask, Django, and FastAPI, as well as database clients and HTTP libraries. These instrumentations generate traces (spans) for every incoming request and outgoing call.

Since `opentelemetry-distro` enables traces by default, these traces would be sent to SigNoz even though this guide only covers metrics. For apps handling many requests, this can generate significant trace volume and costs.

Setting `OTEL_TRACES_EXPORTER="none"` disables traces while keeping metrics working as expected. If you want traces later, see the [Python traces instrumentation guide](https://signoz.io/docs/instrumentation/opentelemetry-python/).
</KeyPointCallout>
</TabItem>
</Tabs>

### Step 2. Install OpenTelemetry packages

```bash
pip install opentelemetry-distro opentelemetry-exporter-otlp
```

### Step 3. Install instrumentation for your dependencies

This command detects your installed packages and adds the corresponding instrumentation libraries:

```bash
opentelemetry-bootstrap --action=install
```

<Admonition type="info">
Run this after installing all your application dependencies. It will only instrument packages that are already installed.

The metrics exported depend on which libraries are instrumented. Check the <a href="https://opentelemetry.io/ecosystem/registry/?language=python&component=instrumentation" target="_blank" rel="noopener noreferrer nofollow">OpenTelemetry Python Instrumentation Registry</a> to see which metrics each instrumentation exports.
</Admonition>

### Step 4. Run your application

```bash
opentelemetry-instrument <your_run_command>
```

For example, with Flask:
```bash
opentelemetry-instrument flask run --no-reload
```

Or with a Python script:
```bash
opentelemetry-instrument python app.py
```

<Admonition type="tip">
For framework-specific run commands (Django, FastAPI, Celery, etc.), see the [Python traces instrumentation guide](https://signoz.io/docs/instrumentation/opentelemetry-python/#framework-instrumentation).
</Admonition>

<KeyPointCallout title="What metrics are exported by zero-code instrumentation?" defaultCollapsed={true}>
Zero-code instrumentation exports **library-specific metrics** from supported frameworks. For example, **Flask instrumentation** exports:
- `http.server.request.duration` - Duration of HTTP server requests (histogram)
- `http.server.active_requests` - Number of concurrent HTTP requests currently in-flight (up-down counter)

Other HTTP frameworks (Django, FastAPI) export similar metrics. Database clients may export connection pool and query metrics. See the <a href="https://opentelemetry.io/ecosystem/registry/?language=python&component=instrumentation" target="_blank" rel="noopener noreferrer nofollow">OpenTelemetry Python Instrumentation Registry</a> for the complete list of available instrumentations.

To collect **system and runtime metrics** (CPU, memory, disk I/O, garbage collection), you need to add the `SystemMetricsInstrumentor`. See the [Runtime instrumentation](#runtime-instrumentation) section below.
</KeyPointCallout>

<details>
<ToggleHeading>
## Runtime instrumentation
</ToggleHeading>

Zero-code instrumentation (`opentelemetry-instrument`) automatically collects metrics from supported HTTP frameworks and database clients. However, **system metrics** (CPU, memory, disk, network) and **Python runtime metrics** (garbage collection, thread counts) require explicitly adding the `SystemMetricsInstrumentor`.

The `opentelemetry-instrumentation-system-metrics` package provides instrumentation for system and runtime metrics such as CPU usage, memory usage, disk I/O, and garbage collection stats.

### Install
```bash
pip install opentelemetry-instrumentation-system-metrics
```

<Admonition type="note" title="Default Exported Metrics">
When you call `SystemMetricsInstrumentor().instrument()`, it automatically exports **35+ metrics** by default including:
- **System metrics**: CPU time/utilization, memory usage, disk I/O, network I/O, swap usage
- **Process metrics**: CPU time, memory usage (RSS), thread count, open file descriptors, context switches
- **CPython runtime metrics**: Garbage collection counts and collected objects

See the [Exported Metrics](#exported-metrics) section below for the complete list.
</Admonition>

### Usage

Add the `SystemMetricsInstrumentor` to your application to collect system and runtime metrics:

```python:app.py
from opentelemetry.instrumentation.system_metrics import SystemMetricsInstrumentor

# Start collecting system and runtime metrics
SystemMetricsInstrumentor().instrument()

# Your application code here...
```

Then run with zero-code instrumentation:
```bash
opentelemetry-instrument python app.py
```

### Exported Metrics

The `SystemMetricsInstrumentor` automatically exports the following metrics:

**System Metrics:**
- `system.cpu.time` - CPU time spent in different modes (user, system, idle, irq)
- `system.cpu.utilization` - CPU utilization percentage
- `system.memory.usage` - Memory usage in bytes
- `system.memory.utilization` - Memory utilization as a ratio
- `system.swap.usage` - Swap space usage in pages
- `system.swap.utilization` - Swap utilization as a ratio
- `system.disk.io` - Disk I/O in bytes (read/write)
- `system.disk.operations` - Disk operation count (read/write)
- `system.disk.time` - Time spent on disk operations
- `system.network.io` - Network I/O in bytes (transmit/receive)
- `system.network.packets` - Network packets (transmit/receive)
- `system.network.errors` - Network errors (transmit/receive)
- `system.network.dropped.packets` - Dropped network packets
- `system.network.connections` - Network connections by family and type
- `system.thread_count` - Number of system threads

**Process Metrics (Semantic Conventions compliant):**
- `process.cpu.time` - Process CPU time (user/system)
- `process.cpu.utilization` - Process CPU utilization
- `process.memory.usage` - Process memory usage (resident set size)
- `process.memory.virtual` - Process virtual memory size
- `process.open_file_descriptor.count` - Open file descriptors (Unix)
- `process.thread.count` - Process thread count
- `process.context_switches` - Context switches (voluntary/involuntary)

**CPython Runtime Metrics:**
- `cpython.gc.collections` - Garbage collection count by generation
- `cpython.gc.collected_objects` - Objects collected by GC
- `cpython.gc.uncollectable_objects` - Uncollectable objects

<Admonition type="warning">
The instrumentor also exports deprecated `process.runtime.*` prefixed metrics (e.g., `process.runtime.cpu.time`, `process.runtime.memory`). These will be removed in future versions. Use the `process.*` metrics listed above instead.
</Admonition>

<Admonition type="info">
Metric names follow the OpenTelemetry semantic conventions. See the complete specifications:
- [System metrics semantic conventions](https://opentelemetry.io/docs/specs/semconv/system/system-metrics/)
- [Process metrics semantic conventions](https://opentelemetry.io/docs/specs/semconv/system/process-metrics/)
- [CPython runtime metrics](https://opentelemetry.io/docs/specs/semconv/runtime/cpython-metrics/)
</Admonition>

</details>

## Validate

Once you have configured your application to start sending metrics to SigNoz, you can start visualizing the metrics in the [metrics explorer](https://signoz.io/docs/metrics-management/metrics-explorer/).

<details>
<ToggleHeading>
## Manual & Custom Instrumentation
</ToggleHeading>

If you need more control over the metrics pipeline (custom export intervals, filtering, custom business metrics), you can set up the SDK manually and create custom metrics.

### Metric types

OpenTelemetry supports four metric types:
- **Counter**: A value that only goes up (e.g., total requests)
- **UpDownCounter**: A value that can go up or down (e.g., queue size)
- **Histogram**: A distribution of values (e.g., request duration)
- **Observable Gauge**: A current value observed asynchronously (e.g., temperature)

### Install packages

```bash
pip install opentelemetry-api \
    opentelemetry-sdk \
    opentelemetry-exporter-otlp-proto-grpc
```

<Admonition type="info">
If you are behind a proxy that only supports HTTP/1.1, use the HTTP exporter instead:
```bash
pip install opentelemetry-exporter-otlp-proto-http
```
</Admonition>

### Create a setup helper

```python:otel_setup.py
import os
import atexit
from opentelemetry import metrics
from opentelemetry.sdk.metrics import MeterProvider
from opentelemetry.sdk.metrics.export import PeriodicExportingMetricReader
from opentelemetry.exporter.otlp.proto.grpc.metric_exporter import OTLPMetricExporter
from opentelemetry.sdk.resources import Resource, SERVICE_NAME

def init_meter_provider():
    """Initialize the OpenTelemetry Meter Provider with OTLP exporter."""

    # Create resource with service name from environment variable
    resource = Resource.create({
        SERVICE_NAME: os.environ.get("OTEL_SERVICE_NAME", "python-app")
    })

    # Create the OTLP exporter
    # It will automatically use OTEL_EXPORTER_OTLP_METRICS_ENDPOINT and headers from env
    exporter = OTLPMetricExporter()

    # Create a periodic reader to export metrics every 10 seconds
    reader = PeriodicExportingMetricReader(
        exporter,
        export_interval_millis=10000
    )

    # Create the MeterProvider with the exporter and resource
    provider = MeterProvider(
        resource=resource,
        metric_readers=[reader]
    )

    # Set the global MeterProvider
    metrics.set_meter_provider(provider)

    # Register shutdown handler
    atexit.register(provider.shutdown)

    return provider
```

<Admonition type="tip">
If using the HTTP exporter, replace the import:
```python
from opentelemetry.exporter.otlp.proto.http.metric_exporter import OTLPMetricExporter
```
</Admonition>

<KeyPointCallout title="Why 10 seconds export interval?" defaultCollapsed={true}>
This example uses a 10-second export interval for faster feedback during development. The OpenTelemetry default is 60 seconds, which reduces network overhead and is better suited for production. Shorter intervals provide more real-time visibility but increase network traffic and storage costs. Adjust based on your monitoring needs.
</KeyPointCallout>

### Example: Flask application with custom metrics

This example demonstrates manual SDK setup with all four metric types:

```python:app.py
from flask import Flask
import time
import random
from typing import Iterable
from opentelemetry import metrics
from opentelemetry.metrics import CallbackOptions, Observation
from otel_setup import init_meter_provider

# Initialize Meter Provider (uses env vars from Step 1)
init_meter_provider()

# Get a meter from the global provider
meter = metrics.get_meter("my-app-meter")

# Counter - tracks total count of events
request_counter = meter.create_counter(
    name="http.requests",
    description="Total request count",
    unit="1"
)

# UpDownCounter - tracks values that can increase or decrease
active_requests = meter.create_up_down_counter(
    name="http.active_requests",
    description="Requests currently in flight",
    unit="1"
)

# Histogram - tracks distribution of values
request_duration = meter.create_histogram(
    name="http.duration_ms",
    description="Request latency in milliseconds",
    unit="ms"
)

# Observable Gauge - asynchronously observes current value
def get_cpu_usage(options: CallbackOptions) -> Iterable[Observation]:
    """Callback function that returns current CPU usage."""
    # In production, use psutil or similar to get real CPU usage
    cpu_value = random.uniform(10.0, 90.0)
    yield Observation(cpu_value, {"cpu": "cpu0"})

cpu_gauge = meter.create_observable_gauge(
    name="system.cpu.usage",
    callbacks=[get_cpu_usage],
    description="Current CPU usage percentage",
    unit="%"
)

app = Flask(__name__)

@app.route("/hello")
def hello():
    start = time.time()

    # Track Active Requests (UpDownCounter)
    active_requests.add(1)

    try:
        # Simulate work
        time.sleep(0.05)
        status = 200
        return "ok"
    finally:
        # Decrement active requests
        active_requests.add(-1)

        # Calculate duration
        duration_ms = (time.time() - start) * 1000

        # Record Histogram
        request_duration.record(duration_ms, {
            "method": "GET",
            "route": "/hello"
        })

        # Record Counter
        request_counter.add(1, {
            "method": "GET",
            "route": "/hello",
            "status": status
        })

if __name__ == "__main__":
    print("Server listening on :8080...")
    app.run(host="0.0.0.0", port=8080)
```

Run the application:
```bash
python app.py
```

### Example: Standalone system metrics collector

If you want to run a standalone process that only collects system metrics (without a web framework):

```python:system_metrics_collector.py
from opentelemetry.instrumentation.system_metrics import SystemMetricsInstrumentor
from otel_setup import init_meter_provider
import time

# Initialize Meter Provider (uses env vars from Step 1)
init_meter_provider()

# Start collecting system and runtime metrics
SystemMetricsInstrumentor().instrument()

print("System metrics collection started...")

# Keep the application running
while True:
    time.sleep(1)
```

Run directly:
```bash
python system_metrics_collector.py
```

</details>

<details>
<ToggleHeading>
## Troubleshooting
</ToggleHeading>

### Metrics not appearing?

1. **Check Environment Variables**: Ensure `OTEL_EXPORTER_OTLP_METRICS_ENDPOINT` is set correctly:
    - For gRPC (default in this guide): `https://ingest.<region>.signoz.cloud:443`
    - For HTTP (if using `otlp-proto-http`): `https://ingest.<region>.signoz.cloud:443/v1/metrics`

2. **Check Exporter Protocol**: This guide uses `otlp-proto-grpc`. If you are behind a proxy that only supports HTTP/1.1, switch to `otlp-proto-http`.

3. **Check Console Errors**: The OpenTelemetry SDK prints errors to stderr by default. Check your application logs for any connection refused or authentication errors.

4. **Resource Attributes**: Ensure `service.name` is set. This helps you filter metrics by service in SigNoz.

5. **Verify Package Installation**: Ensure all required packages are installed:
    ```bash
    pip list | grep opentelemetry
    ```

### Authentication errors

If you see errors like "Unauthorized" or "403 Forbidden":
- Verify your ingestion key is correct in `OTEL_EXPORTER_OTLP_METRICS_HEADERS`
- Ensure the header format is exactly: `signoz-ingestion-key=<your-key>` (no extra spaces)
- Check that your ingestion key is active in the SigNoz Cloud dashboard

### "Connection Refused" errors

- If running locally and sending to SigNoz Cloud, check your internet connection and firewall.
- If sending to a self-hosted collector, ensure the collector is running and listening on port 4317 (gRPC) or 4318 (HTTP).

### SSL/TLS errors

If you encounter SSL certificate errors:
- Ensure you're using `https://` in the endpoint URL
- For self-hosted setups with self-signed certificates, you may need to configure the exporter to trust your CA

</details>

<details>
<ToggleHeading>
## Setup OpenTelemetry Collector (Optional)
</ToggleHeading>

### What is the OpenTelemetry Collector?

Think of the OTel Collector as a middleman between your app and SigNoz. Instead of your application sending data directly to SigNoz, it sends everything to the Collector first, which then forwards it along.

### Why use it?

- **Cleaning up data** — Filter out noisy traces you don't care about, or remove sensitive info before it leaves your servers.
- **Keeping your app lightweight** — Let the Collector handle batching, retries, and compression instead of your application code.
- **Adding context automatically** — The Collector can tag your data with useful info like which Kubernetes pod or cloud region it came from.
- **Future flexibility** — Want to send data to multiple backends later? The Collector makes that easy without changing your app.

See [Switch from direct export to Collector](https://signoz.io/docs/opentelemetry-collection-agents/opentelemetry-collector/switch-to-collector/) for step-by-step instructions to convert your setup.

For more details, see [Why use the OpenTelemetry Collector?](https://signoz.io/docs/opentelemetry-collection-agents/opentelemetry-collector/why-to-use-collector/) and the [Collector configuration guide](https://signoz.io/docs/opentelemetry-collection-agents/opentelemetry-collector/configuration/).

</details>

## Next Steps

- [Create Dashboards](https://signoz.io/docs/userguide/manage-dashboards/) to visualize your metrics.
- [Set up Alerts](https://signoz.io/docs/setup-alerts-notification/) on your metrics.
- [Instrument your Python application with traces](https://signoz.io/docs/instrumentation/opentelemetry-python/) to correlate metrics with traces for better observability.

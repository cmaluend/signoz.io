---
date: 2026-01-17
id: opentelemetry-python
title: Send Metrics from Python application
description: Learn how to instrument your Python application with OpenTelemetry to send metrics to SigNoz

doc_type: howto
---

This guide shows you how to instrument your Python application with OpenTelemetry to send metrics to SigNoz. You will learn how to set up the OpenTelemetry SDK, create custom metrics, and export them to SigNoz.

<KeyPointCallout title="Using self-hosted SigNoz?" defaultCollapsed={true}>
    Most steps are identical. To adapt this guide, update the endpoint and remove the ingestion key header as shown in [Cloud → Self-Hosted](https://signoz.io/docs/ingestion/cloud-vs-self-hosted/#cloud-to-self-hosted).
</KeyPointCallout>

<KeyPointCallout title="Want zero-code instrumentation instead?" defaultCollapsed={true}>
This guide covers manual SDK setup where you write code to initialize OpenTelemetry. This gives you full control over exporters, export intervals, and filtering.

If you want a quick setup without configuring the SDK yourself, see [Zero-Code Instrumentation](#zero-code-instrumentation). It auto-configures the SDK and collects framework metrics automatically, but you have less control over settings.
</KeyPointCallout>

## Prerequisites

- Python 3.9 or later
- A SigNoz Cloud account or self-hosted SigNoz instance

## Send metrics to SigNoz

<Tabs entityName="deployment">
<TabItem value="vm" label="VM" default>
<KeyPointCallout title="What classifies as VM?" defaultCollapsed={true}>
    A VM is a virtual computer that runs on physical hardware. This includes:
    - **Cloud VMs**: AWS EC2, Google Compute Engine, Azure VMs, DigitalOcean Droplets
    - **On-premise VMs**: VMware, VirtualBox, Hyper-V, KVM
    - **Bare metal servers**: Physical servers running Linux/Unix directly

    Use this section if you're deploying your Python application directly on a server or VM without containerization.
</KeyPointCallout>

### Step 1. Set environment variables
Set the following environment variables to configure the OpenTelemetry exporter:
```bash
export OTEL_EXPORTER_OTLP_ENDPOINT="https://ingest.<region>.signoz.cloud:443"
export OTEL_EXPORTER_OTLP_HEADERS="signoz-ingestion-key=<your-ingestion-key>"
export OTEL_SERVICE_NAME="<service-name>"
```
Replace the following:
- `<region>`: Your SigNoz Cloud region (`us`, `eu`, or `in`). See [endpoints](https://signoz.io/docs/ingestion/signoz-cloud/overview/#endpoint).
- `<your-ingestion-key>`: Your SigNoz [ingestion key](https://signoz.io/docs/ingestion/signoz-cloud/keys/).
- `<service-name>`: A descriptive name for your service (e.g., `payment-service`).

</TabItem>

<TabItem value="k8s" label="Kubernetes">
### Step 1. Set environment variables
Add these environment variables to your deployment manifest:
```yaml
env:
- name: OTEL_EXPORTER_OTLP_ENDPOINT
  value: 'https://ingest.<region>.signoz.cloud:443'
- name: OTEL_EXPORTER_OTLP_HEADERS
  value: 'signoz-ingestion-key=<your-ingestion-key>'
- name: OTEL_SERVICE_NAME
  value: '<service-name>'
```
Replace the following:
- `<region>`: Your SigNoz Cloud region (`us`, `eu`, or `in`). See [endpoints](https://signoz.io/docs/ingestion/signoz-cloud/overview/#endpoint).
- `<your-ingestion-key>`: Your SigNoz [ingestion key](https://signoz.io/docs/ingestion/signoz-cloud/keys/).
- `<service-name>`: A descriptive name for your service (e.g., `payment-service`).

</TabItem>

<TabItem value="windows" label="Windows">
### Step 1. Set environment variables (PowerShell)
```powershell
$env:OTEL_EXPORTER_OTLP_ENDPOINT = "https://ingest.<region>.signoz.cloud:443"
$env:OTEL_EXPORTER_OTLP_HEADERS = "signoz-ingestion-key=<your-ingestion-key>"
$env:OTEL_SERVICE_NAME = "<service-name>"
```
Replace the following:
- `<region>`: Your SigNoz Cloud region (`us`, `eu`, or `in`).
- `<your-ingestion-key>`: Your SigNoz [ingestion key](https://signoz.io/docs/ingestion/signoz-cloud/keys/).
- `<service-name>`: A descriptive name for your service.

</TabItem>

<TabItem value="docker" label="Docker">
### Step 1. Set environment variables in Dockerfile
Add environment variables to your Dockerfile:
```dockerfile:Dockerfile
# ... build stages ...

# Set OpenTelemetry environment variables
ENV OTEL_EXPORTER_OTLP_ENDPOINT="https://ingest.<region>.signoz.cloud:443"
ENV OTEL_EXPORTER_OTLP_HEADERS="signoz-ingestion-key=<your-ingestion-key>"
ENV OTEL_SERVICE_NAME="<service-name>"

CMD ["python", "app.py"]
```

Or pass them at runtime using `docker run`:
```bash
docker run -e OTEL_EXPORTER_OTLP_ENDPOINT="https://ingest.<region>.signoz.cloud:443" \
    -e OTEL_EXPORTER_OTLP_HEADERS="signoz-ingestion-key=<your-ingestion-key>" \
    -e OTEL_SERVICE_NAME="<service-name>" \
    your-image:latest
```

Replace the following:
- `<region>`: Your SigNoz Cloud region (`us`, `eu`, or `in`). See [endpoints](https://signoz.io/docs/ingestion/signoz-cloud/overview/#endpoint).
- `<your-ingestion-key>`: Your SigNoz [ingestion key](https://signoz.io/docs/ingestion/signoz-cloud/keys/).
- `<service-name>`: A descriptive name for your service (e.g., `payment-service`).

</TabItem>
</Tabs>

### Step 2. Install OpenTelemetry packages

```bash
pip install opentelemetry-api opentelemetry-sdk opentelemetry-exporter-otlp-proto-grpc
```

<Admonition type="info">
If you are behind a proxy that only supports HTTP/1.1, use the HTTP exporter instead:
```bash
pip install opentelemetry-api opentelemetry-sdk opentelemetry-exporter-otlp-proto-http
```
</Admonition>

### Step 3. Initialize the MeterProvider

Create a setup module to initialize the OpenTelemetry MeterProvider with the OTLP exporter:

```python:otel_setup.py
from opentelemetry import metrics
from opentelemetry.sdk.metrics import MeterProvider
from opentelemetry.sdk.metrics.export import PeriodicExportingMetricReader
from opentelemetry.exporter.otlp.proto.grpc.metric_exporter import OTLPMetricExporter
from opentelemetry.sdk.resources import Resource, SERVICE_NAME
import os

# Create resource with service name
resource = Resource.create({
    SERVICE_NAME: os.environ.get("OTEL_SERVICE_NAME", "python-app")
})

# Create OTLP exporter (reads OTEL_EXPORTER_OTLP_* env vars automatically)
exporter = OTLPMetricExporter()

# Create periodic reader to export metrics every 60 seconds
reader = PeriodicExportingMetricReader(exporter)

# Create and set the global MeterProvider
provider = MeterProvider(resource=resource, metric_readers=[reader])
metrics.set_meter_provider(provider)
```

<Admonition type="tip">
If using the HTTP exporter, replace the import:
```python
from opentelemetry.exporter.otlp.proto.http.metric_exporter import OTLPMetricExporter
```
</Admonition>

### Step 4. Create and record metrics

Get a meter and create instruments to record metrics. Here's an example using a Counter:

```python:app.py
from opentelemetry import metrics
import otel_setup  # Initialize the MeterProvider

# Get a meter from the global provider
meter = metrics.get_meter("my.meter.name")

# Create a counter instrument
work_counter = meter.create_counter(
    name="work.counter",
    unit="1",
    description="Counts the amount of work done"
)

def do_work(work_item):
    # ... do the work ...

    # Record the metric with attributes
    work_counter.add(1, {"work.type": work_item.work_type})
```

<Admonition type="info">
This example shows a Counter, which only increases. OpenTelemetry supports other metric types like UpDownCounter, Histogram, and Observable Gauge. See [All Metric Types](#all-metric-types) for complete examples of each type.
</Admonition>

### Step 5. Run your application

```bash
python app.py
```

## Validate

Once you have configured your application to start sending metrics to SigNoz, you can start visualizing the metrics in the [metrics explorer](https://signoz.io/docs/metrics-management/metrics-explorer/).

<Admonition type="info">
Want to collect system metrics like CPU, memory, and disk usage? See [Runtime Metrics](#runtime-metrics) to add the `SystemMetricsInstrumentor` to your application.
</Admonition>

<details>
<ToggleHeading>
## All Metric Types
</ToggleHeading>

OpenTelemetry supports six metric instrument types. Here's a complete example demonstrating all of them:

### Synchronous Instruments

Synchronous instruments are called inline with your application code.

**Counter** - A value that only increases (e.g., total requests, bytes sent):

```python
counter = meter.create_counter(
    name="requests.total",
    unit="1",
    description="Total number of requests"
)

# Record a value
counter.add(1, {"endpoint": "/api/users"})
```

**UpDownCounter** - A value that can increase or decrease (e.g., active connections, queue size):

```python
updown_counter = meter.create_up_down_counter(
    name="connections.active",
    unit="1",
    description="Number of active connections"
)

# Increment
updown_counter.add(1)

# Decrement
updown_counter.add(-1)
```

**Histogram** - A distribution of values (e.g., request latency, response sizes):

```python
histogram = meter.create_histogram(
    name="request.duration",
    unit="ms",
    description="Request duration in milliseconds"
)

# Record a value
histogram.record(45.5, {"endpoint": "/api/users"})
```

### Asynchronous Instruments

Asynchronous instruments use callback functions that are invoked during metric collection.

**ObservableCounter** - Observes a monotonically increasing value (e.g., CPU time, page faults):

```python
from typing import Iterable
from opentelemetry.metrics import CallbackOptions, Observation

def observable_counter_callback(options: CallbackOptions) -> Iterable[Observation]:
    # Return current cumulative value
    yield Observation(get_total_cpu_time(), {"cpu": "cpu0"})

observable_counter = meter.create_observable_counter(
    name="system.cpu.time",
    callbacks=[observable_counter_callback],
    unit="s",
    description="CPU time"
)
```

**ObservableUpDownCounter** - Observes a value that can go up or down (e.g., memory usage, thread count):

```python
def observable_updown_callback(options: CallbackOptions) -> Iterable[Observation]:
    yield Observation(get_current_memory_usage(), {})

observable_updown = meter.create_observable_up_down_counter(
    name="process.memory.usage",
    callbacks=[observable_updown_callback],
    unit="By",
    description="Memory usage in bytes"
)
```

**ObservableGauge** - Observes a point-in-time value (e.g., temperature, current CPU utilization):

```python
def observable_gauge_callback(options: CallbackOptions) -> Iterable[Observation]:
    yield Observation(get_current_temperature(), {"location": "server-room"})

gauge = meter.create_observable_gauge(
    name="temperature.current",
    callbacks=[observable_gauge_callback],
    unit="Cel",
    description="Current temperature"
)
```

### Complete Example

Here's a complete example showing all instrument types:

```python:metrics_example.py
from typing import Iterable
from opentelemetry import metrics
from opentelemetry.sdk.metrics import MeterProvider
from opentelemetry.sdk.metrics.export import PeriodicExportingMetricReader
from opentelemetry.exporter.otlp.proto.grpc.metric_exporter import OTLPMetricExporter
from opentelemetry.metrics import CallbackOptions, Observation

# Setup
exporter = OTLPMetricExporter()
reader = PeriodicExportingMetricReader(exporter)
provider = MeterProvider(metric_readers=[reader])
metrics.set_meter_provider(provider)

meter = metrics.get_meter("example.meter", "1.0.0")

# Callback functions for async instruments
def observable_counter_func(options: CallbackOptions) -> Iterable[Observation]:
    yield Observation(1, {})

def observable_updown_func(options: CallbackOptions) -> Iterable[Observation]:
    yield Observation(-10, {})

def observable_gauge_func(options: CallbackOptions) -> Iterable[Observation]:
    yield Observation(9, {})

# Counter
counter = meter.create_counter("counter")
counter.add(1)

# Observable Counter
observable_counter = meter.create_observable_counter(
    "observable_counter",
    [observable_counter_func],
)

# UpDownCounter
updown_counter = meter.create_up_down_counter("updown_counter")
updown_counter.add(1)
updown_counter.add(-5)

# Observable UpDownCounter
observable_updown = meter.create_observable_up_down_counter(
    "observable_updown_counter",
    [observable_updown_func]
)

# Histogram
histogram = meter.create_histogram("histogram")
histogram.record(99.9)

# Observable Gauge
gauge = meter.create_observable_gauge("gauge", [observable_gauge_func])

# Keep running to allow metrics to be exported
import time
while True:
    counter.add(1)
    time.sleep(1)
```

</details>

<details>
<ToggleHeading>
## Zero-Code Instrumentation
</ToggleHeading>

Zero-code instrumentation automatically collects metrics from supported frameworks without code changes. This approach is ideal if you want quick setup with framework-provided metrics.

### Step 1. Set environment variables

Use the same environment variables from Step 1 above, but add `OTEL_TRACES_EXPORTER="none"` to disable traces if you only want metrics:

<Tabs entityName="deployment">
<TabItem value="vm" label="VM" default>
```bash
export OTEL_EXPORTER_OTLP_ENDPOINT="https://ingest.<region>.signoz.cloud:443"
export OTEL_EXPORTER_OTLP_HEADERS="signoz-ingestion-key=<your-ingestion-key>"
export OTEL_SERVICE_NAME="<service-name>"
export OTEL_TRACES_EXPORTER="none"
```
</TabItem>

<TabItem value="k8s" label="Kubernetes">
```yaml
env:
- name: OTEL_EXPORTER_OTLP_ENDPOINT
  value: 'https://ingest.<region>.signoz.cloud:443'
- name: OTEL_EXPORTER_OTLP_HEADERS
  value: 'signoz-ingestion-key=<your-ingestion-key>'
- name: OTEL_SERVICE_NAME
  value: '<service-name>'
- name: OTEL_TRACES_EXPORTER
  value: 'none'
```
</TabItem>

<TabItem value="windows" label="Windows">
```powershell
$env:OTEL_EXPORTER_OTLP_ENDPOINT = "https://ingest.<region>.signoz.cloud:443"
$env:OTEL_EXPORTER_OTLP_HEADERS = "signoz-ingestion-key=<your-ingestion-key>"
$env:OTEL_SERVICE_NAME = "<service-name>"
$env:OTEL_TRACES_EXPORTER = "none"
```
</TabItem>

<TabItem value="docker" label="Docker">
```dockerfile:Dockerfile
ENV OTEL_EXPORTER_OTLP_ENDPOINT="https://ingest.<region>.signoz.cloud:443"
ENV OTEL_EXPORTER_OTLP_HEADERS="signoz-ingestion-key=<your-ingestion-key>"
ENV OTEL_SERVICE_NAME="<service-name>"
ENV OTEL_TRACES_EXPORTER="none"
```
</TabItem>
</Tabs>

<KeyPointCallout title="Why explicitly disable traces?" defaultCollapsed={true}>
The bootstrap command installs instrumentations for all detected libraries, including web frameworks like Flask, Django, and FastAPI. These instrumentations generate traces (spans) for every incoming request.

Since `opentelemetry-distro` enables traces by default, these traces would be sent to SigNoz even though you may only want metrics. For apps handling many requests, this can generate significant trace volume and costs.

Setting `OTEL_TRACES_EXPORTER="none"` disables traces while keeping metrics working. If you want traces later, see the [Python traces instrumentation guide](https://signoz.io/docs/instrumentation/opentelemetry-python/).
</KeyPointCallout>

### Step 2. Install OpenTelemetry packages

```bash
pip install opentelemetry-distro opentelemetry-exporter-otlp
```

### Step 3. Install instrumentation for your dependencies

This command detects your installed packages and adds the corresponding instrumentation libraries:

```bash
opentelemetry-bootstrap --action=install
```

<Admonition type="info">
Run this after installing all your application dependencies. It will only instrument packages that are already installed.

The metrics exported depend on which libraries are instrumented. Check the <a href="https://opentelemetry.io/ecosystem/registry/?language=python&component=instrumentation" target="_blank" rel="noopener noreferrer nofollow">OpenTelemetry Python Instrumentation Registry</a> to see which metrics each instrumentation exports.
</Admonition>

### Step 4. Run your application

```bash
opentelemetry-instrument <your_run_command>
```

Choose your framework below to see the specific run command:

<LibraryTabs
    className="mb-8"
    defaultCategory="all"
    defaultLibrary="flask"
    categoryLabels={{
        web: 'Web Frameworks',
        worker: 'Background Workers',
    }}
>
    <LibraryTab value="flask" label="Flask" category="web">

        ```bash
        opentelemetry-instrument flask run --no-reload
        ```

        Or if running directly:

        ```bash
        opentelemetry-instrument python app.py
        ```

        <Admonition type="warning">
        Always use `--no-reload` with Flask. The reloader spawns a child process that breaks OpenTelemetry instrumentation.
        </Admonition>

    </LibraryTab>
    <LibraryTab value="django" label="Django" category="web">

        Set the `DJANGO_SETTINGS_MODULE` environment variable first:

        ```bash
        export DJANGO_SETTINGS_MODULE=myproject.settings
        ```

        Then run:

        ```bash
        opentelemetry-instrument python manage.py runserver --noreload
        ```

        <Admonition type="warning">
        Always use `--noreload` with Django. The auto-reload mechanism spawns child processes that break OpenTelemetry instrumentation.
        </Admonition>

    </LibraryTab>
    <LibraryTab value="fastapi" label="FastAPI" category="web">

        ```bash
        opentelemetry-instrument uvicorn main:app --host 0.0.0.0 --port 8000
        ```

        <Admonition type="warning">
        Do not use `--reload` with Uvicorn when instrumenting. The reload mode spawns new processes that break instrumentation.
        </Admonition>

    </LibraryTab>
    <LibraryTab value="celery" label="Celery" category="worker">

        ```bash
        opentelemetry-instrument celery -A tasks worker --loglevel=info
        ```

        Replace `tasks` with your Celery app module name.

        <Admonition type="info">
        Celery instrumentation has limited metrics support. It only exports `flower.task.runtime.seconds` (task execution time). For comprehensive task metrics, consider adding custom instrumentation.
        </Admonition>

    </LibraryTab>
    <LibraryTab value="other" label="Other" category="web">

        For any Python script:

        ```bash
        opentelemetry-instrument python app.py
        ```

    </LibraryTab>
</LibraryTabs>

<KeyPointCallout title="What metrics are exported by zero-code instrumentation?" defaultCollapsed={true}>
Zero-code instrumentation exports **library-specific metrics** from supported frameworks. For example, **Flask instrumentation** exports:
- `http.server.request.duration` - Duration of HTTP server requests (histogram)
- `http.server.active_requests` - Number of concurrent HTTP requests currently in-flight (up-down counter)

Other HTTP frameworks (Django, FastAPI) export similar metrics. Database clients may export connection pool and query metrics. See the <a href="https://opentelemetry.io/ecosystem/registry/?language=python&component=instrumentation" target="_blank" rel="noopener noreferrer nofollow">OpenTelemetry Python Instrumentation Registry</a> for the complete list of available instrumentations.

</KeyPointCallout>

</details>

<details>
<ToggleHeading>
## Runtime Metrics
</ToggleHeading>

To collect system metrics (CPU, memory, disk, network) and Python runtime metrics (garbage collection, thread counts), use the `SystemMetricsInstrumentor`. This works with both manual SDK setup and zero-code instrumentation.

### Install

```bash
pip install opentelemetry-instrumentation-system-metrics
```

### Usage

<Tabs>
<TabItem value="manual" label="Manual SDK" default>

Add the instrumentor after initializing your MeterProvider:

```python:app.py
from opentelemetry.instrumentation.system_metrics import SystemMetricsInstrumentor
import otel_setup  # Your MeterProvider setup from Step 3

# Start collecting system and runtime metrics
SystemMetricsInstrumentor().instrument()

# Your application code here...
```

Run your application:
```bash
python app.py
```

</TabItem>
<TabItem value="zero-code" label="Zero-Code">

Add the instrumentor to your application code:

```python:app.py
from opentelemetry.instrumentation.system_metrics import SystemMetricsInstrumentor

# Start collecting system and runtime metrics
SystemMetricsInstrumentor().instrument()

# Your application code here...
```

Then run with `opentelemetry-instrument`:
```bash
opentelemetry-instrument python app.py
```

</TabItem>
</Tabs>

### Exported Metrics

When you call `SystemMetricsInstrumentor().instrument()`, it automatically exports **35+ metrics** including:

**System Metrics:**
- `system.cpu.time` - CPU time spent in different modes (user, system, idle)
- `system.cpu.utilization` - CPU utilization percentage
- `system.memory.usage` - Memory usage in bytes
- `system.memory.utilization` - Memory utilization as a ratio
- `system.disk.io` - Disk I/O in bytes (read/write)
- `system.network.io` - Network I/O in bytes (transmit/receive)

**Process Metrics:**
- `process.cpu.time` - Process CPU time (user/system)
- `process.memory.usage` - Process memory usage (resident set size)
- `process.thread.count` - Process thread count

**CPython Runtime Metrics:**
- `cpython.gc.collections` - Garbage collection count by generation
- `cpython.gc.collected_objects` - Objects collected by GC

See the OpenTelemetry semantic conventions for the complete list:
- <a href="https://opentelemetry.io/docs/specs/semconv/system/system-metrics/" target="_blank" rel="noopener noreferrer nofollow">System metrics</a>
- <a href="https://opentelemetry.io/docs/specs/semconv/system/process-metrics/" target="_blank" rel="noopener noreferrer nofollow">Process metrics</a>
- <a href="https://opentelemetry.io/docs/specs/semconv/runtime/cpython-metrics/" target="_blank" rel="noopener noreferrer nofollow">CPython runtime metrics</a>

</details>

<details>
<ToggleHeading>
## Troubleshooting
</ToggleHeading>

### Metrics not appearing?

1. **Check Environment Variables**: Ensure `OTEL_EXPORTER_OTLP_ENDPOINT` is set correctly:
    - For gRPC (default): `https://ingest.<region>.signoz.cloud:443`
    - For HTTP: `https://ingest.<region>.signoz.cloud:443/v1/metrics`

2. **Check Exporter Protocol**: This guide uses `otlp-proto-grpc`. If you are behind a proxy that only supports HTTP/1.1, switch to `otlp-proto-http`.

3. **Check Console Errors**: The OpenTelemetry SDK prints errors to stderr by default. Check your application logs for any connection refused or authentication errors.

4. **Resource Attributes**: Ensure `OTEL_SERVICE_NAME` is set. This helps you filter metrics by service in SigNoz.

5. **Verify Package Installation**: Ensure all required packages are installed:
    ```bash
    pip list | grep opentelemetry
    ```

### Authentication errors

If you see errors like "Unauthorized" or "403 Forbidden":
- Verify your ingestion key is correct in `OTEL_EXPORTER_OTLP_HEADERS`
- Ensure the header format is exactly: `signoz-ingestion-key=<your-key>` (no extra spaces)
- Check that your ingestion key is active in the SigNoz Cloud dashboard

### "Connection Refused" errors

- If running locally and sending to SigNoz Cloud, check your internet connection and firewall.
- If sending to a self-hosted collector, ensure the collector is running and listening on port 4317 (gRPC) or 4318 (HTTP).

### SSL/TLS errors

If you encounter SSL certificate errors:
- Ensure you're using `https://` in the endpoint URL
- For self-hosted setups with self-signed certificates, you may need to configure the exporter to trust your CA

</details>

<details>
<ToggleHeading>
## Setup OpenTelemetry Collector (Optional)
</ToggleHeading>

### What is the OpenTelemetry Collector?

Think of the OTel Collector as a middleman between your app and SigNoz. Instead of your application sending data directly to SigNoz, it sends everything to the Collector first, which then forwards it along.

### Why use it?

- **Cleaning up data** — Filter out noisy metrics you don't care about, or remove sensitive info before it leaves your servers.
- **Keeping your app lightweight** — Let the Collector handle batching, retries, and compression instead of your application code.
- **Adding context automatically** — The Collector can tag your data with useful info like which Kubernetes pod or cloud region it came from.
- **Future flexibility** — Want to send data to multiple backends later? The Collector makes that easy without changing your app.

See [Switch from direct export to Collector](https://signoz.io/docs/opentelemetry-collection-agents/opentelemetry-collector/switch-to-collector/) for step-by-step instructions to convert your setup.

For more details, see [Why use the OpenTelemetry Collector?](https://signoz.io/docs/opentelemetry-collection-agents/opentelemetry-collector/why-to-use-collector/) and the [Collector configuration guide](https://signoz.io/docs/opentelemetry-collection-agents/opentelemetry-collector/configuration/).

</details>

## Next Steps

- [Create Dashboards](https://signoz.io/docs/userguide/manage-dashboards/) to visualize your metrics.
- [Set up Alerts](https://signoz.io/docs/setup-alerts-notification/) on your metrics.
- [Instrument your Python application with traces](https://signoz.io/docs/instrumentation/opentelemetry-python/) to correlate metrics with traces for better observability.

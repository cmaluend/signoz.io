---
date: 2026-01-12
id: opentelemetry-python
title: Send Metrics from Python application
description: Learn how to instrument your Python application with OpenTelemetry to send metrics to SigNoz

doc_type: howto
---

This guide shows you how to instrument your Python application with OpenTelemetry to send metrics to SigNoz. You will learn how to collect system and runtime metrics, use auto-instrumentation, and create custom metrics.

<KeyPointCallout title="Using self-hosted SigNoz?" defaultCollapsed={true}>
    Most steps are identical. To adapt this guide, update the endpoint and remove the ingestion key header as shown in [Cloud → Self-Hosted](https://signoz.io/docs/ingestion/cloud-vs-self-hosted/#cloud-to-self-hosted).
</KeyPointCallout>

## Prerequisites

- Python 3.9 or later
- A SigNoz Cloud account or self-hosted SigNoz instance

## Send metrics to SigNoz

<Tabs entityName="deployment">
<TabItem value="vm" label="VM" default>
<KeyPointCallout title="What classifies as VM?" defaultCollapsed={true}>
    A VM is a virtual computer that runs on physical hardware. This includes:
    - **Cloud VMs**: AWS EC2, Google Compute Engine, Azure VMs, DigitalOcean Droplets
    - **On-premise VMs**: VMware, VirtualBox, Hyper-V, KVM
    - **Bare metal servers**: Physical servers running Linux/Unix directly

    Use this section if you're deploying your Python application directly on a server or VM without containerization.
</KeyPointCallout>

### Step 1. Set environment variables
Set the following environment variables to configure the OpenTelemetry exporter:
```bash
export OTEL_EXPORTER_OTLP_METRICS_ENDPOINT="https://ingest.<region>.signoz.cloud:443"
export OTEL_EXPORTER_OTLP_METRICS_HEADERS="signoz-ingestion-key=<your-ingestion-key>"
export OTEL_SERVICE_NAME="<service-name>"
```
Replace the following:
- `<region>`: Your SigNoz Cloud region (`us`, `eu`, or `in`). See [endpoints](https://signoz.io/docs/ingestion/signoz-cloud/overview/#endpoint).
- `<your-ingestion-key>`: Your SigNoz [ingestion key](https://signoz.io/docs/ingestion/signoz-cloud/keys/).
- `<service-name>`: A descriptive name for your service (e.g., `payment-service`).

</TabItem>

<TabItem value="k8s" label="Kubernetes">
### Step 1. Set environment variables
Add these environment variables to your deployment manifest:
```yaml
env:
- name: OTEL_EXPORTER_OTLP_METRICS_ENDPOINT
  value: 'https://ingest.<region>.signoz.cloud:443'
- name: OTEL_EXPORTER_OTLP_METRICS_HEADERS
  value: 'signoz-ingestion-key=<your-ingestion-key>'
- name: OTEL_SERVICE_NAME
  value: '<service-name>'
```
Replace the following:
- `<region>`: Your SigNoz Cloud region (`us`, `eu`, or `in`). See [endpoints](https://signoz.io/docs/ingestion/signoz-cloud/overview/#endpoint).
- `<your-ingestion-key>`: Your SigNoz [ingestion key](https://signoz.io/docs/ingestion/signoz-cloud/keys/).
- `<service-name>`: A descriptive name for your service (e.g., `payment-service`).
</TabItem>

<TabItem value="windows" label="Windows">
### Step 1. Set environment variables (PowerShell)
```powershell
$env:OTEL_EXPORTER_OTLP_METRICS_ENDPOINT = "https://ingest.<region>.signoz.cloud:443"
$env:OTEL_EXPORTER_OTLP_METRICS_HEADERS = "signoz-ingestion-key=<your-ingestion-key>"
$env:OTEL_SERVICE_NAME = "<service-name>"
```
Replace the following:
- `<region>`: Your SigNoz Cloud region (`us`, `eu`, or `in`).
- `<your-ingestion-key>`: Your SigNoz [ingestion key](https://signoz.io/docs/ingestion/signoz-cloud/keys/).
- `<service-name>`: A descriptive name for your service.
</TabItem>

<TabItem value="docker" label="Docker">
### Step 1. Set environment variables in Dockerfile
Add environment variables to your Dockerfile:
```dockerfile:Dockerfile
# ... build stages ...

# Set OpenTelemetry environment variables
ENV OTEL_EXPORTER_OTLP_METRICS_ENDPOINT="https://ingest.<region>.signoz.cloud:443"
ENV OTEL_EXPORTER_OTLP_METRICS_HEADERS="signoz-ingestion-key=<your-ingestion-key>"
ENV OTEL_SERVICE_NAME="<service-name>"

CMD ["python", "app.py"]
```

Or pass them at runtime using `docker run`:
```bash
docker run -e OTEL_EXPORTER_OTLP_METRICS_ENDPOINT="https://ingest.<region>.signoz.cloud:443" \
    -e OTEL_EXPORTER_OTLP_METRICS_HEADERS="signoz-ingestion-key=<your-ingestion-key>" \
    -e OTEL_SERVICE_NAME="<service-name>" \
    your-image:latest
```

Replace the following:
- `<region>`: Your SigNoz Cloud region (`us`, `eu`, or `in`). See [endpoints](https://signoz.io/docs/ingestion/signoz-cloud/overview/#endpoint).
- `<your-ingestion-key>`: Your SigNoz [ingestion key](https://signoz.io/docs/ingestion/signoz-cloud/keys/).
- `<service-name>`: A descriptive name for your service (e.g., `payment-service`).
</TabItem>
</Tabs>

### Step 2. Install OpenTelemetry packages

Run the following command to install the necessary packages for metrics and OTLP export:

```bash
pip install opentelemetry-api \
    opentelemetry-sdk \
    opentelemetry-exporter-otlp-proto-grpc
```

<Admonition type="info">
If you are behind a proxy that only supports HTTP/1.1, use the HTTP exporter instead:
```bash
pip install opentelemetry-exporter-otlp-proto-http
```
</Admonition>

### Step 3. Initialize the Meter Provider

Create a helper function to configure the OpenTelemetry Meter Provider. This provider is responsible for creating meters and exporting metrics. It automatically uses the environment variables configured in Step 1.

```python:otel_setup.py
import os
import atexit
from opentelemetry import metrics
from opentelemetry.sdk.metrics import MeterProvider
from opentelemetry.sdk.metrics.export import PeriodicExportingMetricReader
from opentelemetry.exporter.otlp.proto.grpc.metric_exporter import OTLPMetricExporter
from opentelemetry.sdk.resources import Resource, SERVICE_NAME

def init_meter_provider():
    """Initialize the OpenTelemetry Meter Provider with OTLP exporter."""

    # Create resource with service name from environment variable
    resource = Resource.create({
        SERVICE_NAME: os.environ.get("OTEL_SERVICE_NAME", "python-app")
    })

    # Create the OTLP exporter
    # It will automatically use OTEL_EXPORTER_OTLP_METRICS_ENDPOINT and headers from env
    exporter = OTLPMetricExporter()

    # Create a periodic reader to export metrics every 10 seconds
    reader = PeriodicExportingMetricReader(
        exporter,
        export_interval_millis=10000
    )

    # Create the MeterProvider with the exporter and resource
    provider = MeterProvider(
        resource=resource,
        metric_readers=[reader]
    )

    # Set the global MeterProvider
    metrics.set_meter_provider(provider)

    # Register shutdown handler
    atexit.register(provider.shutdown)

    return provider
```

<Admonition type="tip">
If using the HTTP exporter, replace the import and exporter initialization:
```python
from opentelemetry.exporter.otlp.proto.http.metric_exporter import OTLPMetricExporter
```
</Admonition>

<KeyPointCallout title="Why 10 seconds export interval?" defaultCollapsed={true}>
This guide uses a 10-second export interval for faster feedback during development. The OpenTelemetry default is 60 seconds, which reduces network overhead and is better suited for production. Shorter intervals provide more real-time visibility but increase network traffic and storage costs. Adjust based on your monitoring needs.
</KeyPointCallout>

### Step 4. Instrument your application

Here's a complete example that tracks HTTP requests with a counter metric:

```python:app.py
from flask import Flask
import time
from opentelemetry import metrics
from otel_setup import init_meter_provider

# Initialize Meter Provider
init_meter_provider()

# Get a meter from the global provider
meter = metrics.get_meter("my-app-meter")

# Define a counter metric
request_counter = meter.create_counter(
    name="http.requests",
    description="Total request count",
    unit="1"
)

app = Flask(__name__)

@app.route("/hello")
def hello():
    start = time.time()

    # Simulate work
    time.sleep(0.05)

    # Record Count
    request_counter.add(1, {
        "method": "GET",
        "route": "/hello",
        "status": 200
    })

    duration = time.time() - start
    print(f"Request completed in {duration:.3f}s")

    return "ok"

if __name__ == "__main__":
    print("Server listening on :8080...")
    app.run(host="0.0.0.0", port=8080)
```

## Library instrumentation

You can use OpenTelemetry's auto-instrumentation packages to automatically collect metrics, or create custom metrics manually.

<Tabs>
<TabItem value="runtime" label="Runtime Metrics" default>

The `opentelemetry-instrumentation-system-metrics` package provides auto-instrumentation for system and runtime metrics such as CPU usage, memory usage, disk I/O, and garbage collection stats.

### Install
```bash
pip install opentelemetry-instrumentation-system-metrics
```

### Usage

```python:app.py
from opentelemetry import metrics
from opentelemetry.instrumentation.system_metrics import SystemMetricsInstrumentor
from otel_setup import init_meter_provider

# Initialize Meter Provider (uses env vars from Step 1)
init_meter_provider()

# Start collecting system and runtime metrics
SystemMetricsInstrumentor().instrument()

print("System metrics collection started...")

# Keep the application running
import time
while True:
    time.sleep(1)
```

<details>
<ToggleHeading>
### Exported Metrics
</ToggleHeading>

The `SystemMetricsInstrumentor` automatically exports the following metrics:

**System Metrics:**
- `system.cpu.time` - CPU time spent in different modes (user, system, idle, irq)
- `system.cpu.utilization` - CPU utilization percentage
- `system.memory.usage` - Memory usage in bytes
- `system.memory.utilization` - Memory utilization as a ratio
- `system.swap.usage` - Swap space usage in pages
- `system.swap.utilization` - Swap utilization as a ratio
- `system.disk.io` - Disk I/O in bytes (read/write)
- `system.disk.operations` - Disk operation count (read/write)
- `system.disk.time` - Time spent on disk operations
- `system.network.io` - Network I/O in bytes (transmit/receive)
- `system.network.packets` - Network packets (transmit/receive)
- `system.network.errors` - Network errors (transmit/receive)
- `system.network.dropped.packets` - Dropped network packets
- `system.network.connections` - Network connections by family and type
- `system.thread_count` - Number of system threads

**Process Metrics (Semantic Conventions compliant):**
- `process.cpu.time` - Process CPU time (user/system)
- `process.cpu.utilization` - Process CPU utilization
- `process.memory.usage` - Process memory usage (resident set size)
- `process.memory.virtual` - Process virtual memory size
- `process.open_file_descriptor.count` - Open file descriptors (Unix)
- `process.thread.count` - Process thread count
- `process.context_switches` - Context switches (voluntary/involuntary)

**CPython Runtime Metrics:**
- `cpython.gc.collections` - Garbage collection count by generation
- `cpython.gc.collected_objects` - Objects collected by GC
- `cpython.gc.uncollectable_objects` - Uncollectable objects

<Admonition type="warning">
The instrumentor also exports deprecated `process.runtime.*` prefixed metrics (e.g., `process.runtime.cpu.time`, `process.runtime.memory`). These will be removed in future versions. Use the `process.*` metrics listed above instead.
</Admonition>

<Admonition type="info">
Metric names follow the OpenTelemetry semantic conventions. See the complete specifications:
- [System metrics semantic conventions](https://opentelemetry.io/docs/specs/semconv/system/system-metrics/)
- [Process metrics semantic conventions](https://opentelemetry.io/docs/specs/semconv/system/process-metrics/)
- [CPython runtime metrics](https://opentelemetry.io/docs/specs/semconv/runtime/cpython-metrics/)
</Admonition>

</details>

</TabItem>

<TabItem value="custom" label="Custom Instrumentation">

Create custom metrics to track business logic with all metric types: Counter, UpDownCounter, Histogram, and Observable Gauge.

### Metric Types

- **Counter**: A value that only goes up (e.g., total requests)
- **UpDownCounter**: A value that can go up or down (e.g., queue size)
- **Histogram**: A distribution of values (e.g., request duration)
- **Observable Gauge**: A current value observed asynchronously (e.g., temperature)

### Usage

```python:app.py
from flask import Flask
import time
import random
from typing import Iterable
from opentelemetry import metrics
from opentelemetry.metrics import CallbackOptions, Observation
from otel_setup import init_meter_provider

# Initialize Meter Provider (uses env vars from Step 1)
init_meter_provider()

# Get a meter from the global provider
meter = metrics.get_meter("custom-metrics")

# Counter - tracks total count of events
request_counter = meter.create_counter(
    name="http.requests",
    description="Total request count",
    unit="1"
)

# UpDownCounter - tracks values that can increase or decrease
active_requests = meter.create_up_down_counter(
    name="http.active_requests",
    description="Requests currently in flight",
    unit="1"
)

# Histogram - tracks distribution of values
request_duration = meter.create_histogram(
    name="http.duration_ms",
    description="Request latency in milliseconds",
    unit="ms"
)

# Observable Gauge - asynchronously observes current value
def get_cpu_usage(options: CallbackOptions) -> Iterable[Observation]:
    """Callback function that returns current CPU usage."""
    # In production, use psutil or similar to get real CPU usage
    cpu_value = random.uniform(10.0, 90.0)
    yield Observation(cpu_value, {"cpu": "cpu0"})

cpu_gauge = meter.create_observable_gauge(
    name="system.cpu.usage",
    callbacks=[get_cpu_usage],
    description="Current CPU usage percentage",
    unit="%"
)

app = Flask(__name__)

@app.route("/hello")
def hello():
    start = time.time()

    # Track Active Requests (UpDownCounter)
    active_requests.add(1)

    try:
        # Simulate work
        time.sleep(0.05)
        status = 200
        return "ok"
    finally:
        # Decrement active requests
        active_requests.add(-1)

        # Calculate duration
        duration_ms = (time.time() - start) * 1000

        # Record Histogram
        request_duration.record(duration_ms, {
            "method": "GET",
            "route": "/hello"
        })

        # Record Counter
        request_counter.add(1, {
            "method": "GET",
            "route": "/hello",
            "status": status
        })

if __name__ == "__main__":
    print("Server listening on :8080...")
    app.run(host="0.0.0.0", port=8080)
```

<details>
<ToggleHeading>
### Exported Metrics
</ToggleHeading>

The custom instrumentation example above exports the following metrics:

- `http.requests` (Counter) - Total count of HTTP requests with attributes for method, route, and status code
- `http.duration_ms` (Histogram) - Distribution of HTTP request latencies in milliseconds
- `http.active_requests` (UpDownCounter) - Current number of requests being processed
- `system.cpu.usage` (Observable Gauge) - Current CPU usage percentage, observed asynchronously

You can create additional metrics based on your application's needs by using the meter to create counters, histograms, up/down counters, and observable gauges to track business metrics, performance indicators, or any other relevant data.

</details>

</TabItem>
</Tabs>


## Validate

Once you have configured your application to start sending metrics to SigNoz, you can start visualizing the metrics in the [metrics explorer](https://signoz.io/docs/metrics-management/metrics-explorer/).

<details>
<ToggleHeading>
## Troubleshooting
</ToggleHeading>

### Metrics not appearing?

1. **Check Environment Variables**: Ensure `OTEL_EXPORTER_OTLP_METRICS_ENDPOINT` is set correctly:
    - For gRPC (default in this guide): `https://ingest.<region>.signoz.cloud:443`
    - For HTTP (if using `otlp-proto-http`): `https://ingest.<region>.signoz.cloud:443/v1/metrics`

2. **Check Exporter Protocol**: This guide uses `otlp-proto-grpc`. If you are behind a proxy that only supports HTTP/1.1, switch to `otlp-proto-http`.

3. **Check Console Errors**: The OpenTelemetry SDK prints errors to stderr by default. Check your application logs for any connection refused or authentication errors.

4. **Resource Attributes**: Ensure `service.name` is set. This helps you filter metrics by service in SigNoz.

5. **Verify Package Installation**: Ensure all required packages are installed:
    ```bash
    pip list | grep opentelemetry
    ```

### Authentication errors

If you see errors like "Unauthorized" or "403 Forbidden":
- Verify your ingestion key is correct in `OTEL_EXPORTER_OTLP_METRICS_HEADERS`
- Ensure the header format is exactly: `signoz-ingestion-key=<your-key>` (no extra spaces)
- Check that your ingestion key is active in the SigNoz Cloud dashboard

### "Connection Refused" errors

- If running locally and sending to SigNoz Cloud, check your internet connection and firewall.
- If sending to a self-hosted collector, ensure the collector is running and listening on port 4317 (gRPC) or 4318 (HTTP).

### SSL/TLS errors

If you encounter SSL certificate errors:
- Ensure you're using `https://` in the endpoint URL
- For self-hosted setups with self-signed certificates, you may need to configure the exporter to trust your CA

</details>

<details>
<ToggleHeading>
## Setup OpenTelemetry Collector (Optional)
</ToggleHeading>

### What is the OpenTelemetry Collector?

Think of the OTel Collector as a middleman between your app and SigNoz. Instead of your application sending data directly to SigNoz, it sends everything to the Collector first, which then forwards it along.

### Why use it?

- **Cleaning up data** — Filter out noisy traces you don't care about, or remove sensitive info before it leaves your servers.
- **Keeping your app lightweight** — Let the Collector handle batching, retries, and compression instead of your application code.
- **Adding context automatically** — The Collector can tag your data with useful info like which Kubernetes pod or cloud region it came from.
- **Future flexibility** — Want to send data to multiple backends later? The Collector makes that easy without changing your app.

See [Switch from direct export to Collector](https://signoz.io/docs/opentelemetry-collection-agents/opentelemetry-collector/switch-to-collector/) for step-by-step instructions to convert your setup.

For more details, see [Why use the OpenTelemetry Collector?](https://signoz.io/docs/opentelemetry-collection-agents/opentelemetry-collector/why-to-use-collector/) and the [Collector configuration guide](https://signoz.io/docs/opentelemetry-collection-agents/opentelemetry-collector/configuration/).

</details>

## Next Steps

- [Create Dashboards](https://signoz.io/docs/userguide/manage-dashboards/) to visualize your metrics.
- [Set up Alerts](https://signoz.io/docs/alerts-management/notification-channel/slack/) on your metrics.
- [Instrument your Python application with traces](https://signoz.io/docs/instrumentation/opentelemetry-python/) to correlate metrics with traces for better observability.

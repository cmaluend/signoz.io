---
date: 2025-11-18
id: java

title: Java OpenTelemetry Instrumentation
description: Learn how to instrument your Java application with OpenTelemetry and send telemetry data to SigNoz.
hide_table_of_contents: true
---

This document contains instructions on how to set up OpenTelemetry instrumentation in your Java applications and view your application traces in SigNoz.

OpenTelemetry Java is the language-specific implementation of OpenTelemetry in Java.

## Requirements

Java 8 or higher

<Tabs entityName="plans">
<TabItem value="signoz-cloud" label="SigNoz Cloud" default>

## Send Traces to SigNoz Cloud

OpenTelemetry provides a Java JAR agent that can be attached to any Java 8+ application and dynamically injects bytecode to capture telemetry from a number of popular libraries and frameworks.

Based on your application environment, you can choose the setup below to send traces to SigNoz Cloud.

<Tabs>
<TabItem value="vm" label="VM" default>

From VMs, there are two ways to send data to SigNoz Cloud.

- [Send traces directly to SigNoz Cloud](#send-traces-directly-to-signoz-cloud)
- [Send traces via OTel Collector binary](#send-traces-via-otel-collector-binary) (recommended)

#### Send traces directly to SigNoz Cloud

OpenTelemetry Java agent can send traces directly to SigNoz Cloud.

**Step 1.** Download OTel Java binary agent

```bash
wget https://github.com/open-telemetry/opentelemetry-java-instrumentation/releases/latest/download/opentelemetry-javaagent.jar
```

**Step 2.** Run your application

```bash
OTEL_RESOURCE_ATTRIBUTES=service.name=<service_name> \
OTEL_EXPORTER_OTLP_HEADERS="signoz-ingestion-key=<your-ingestion-key>" \
OTEL_EXPORTER_OTLP_ENDPOINT="https://ingest.<region>.signoz.cloud:443" \
java -javaagent:$PWD/opentelemetry-javaagent.jar -jar <my-app>.jar
```

- Set the `<region>` to match your SigNoz Cloud [region](https://signoz.io/docs/ingestion/signoz-cloud/overview/#endpoint)
- Replace `<your-ingestion-key>` with your SigNoz [ingestion key](https://signoz.io/docs/ingestion/signoz-cloud/keys/)
- `<service_name>` is name of your service

If your applications do not appear in the services section, please refer to the [troubleshooting section](#troubleshooting-your-installation).

---

#### Send traces via OTel Collector binary

**Step 1.** Download OTel Java binary agent

```bash
wget https://github.com/open-telemetry/opentelemetry-java-instrumentation/releases/latest/download/opentelemetry-javaagent.jar
```

**Step 2.** Run your application

```bash
java -javaagent:$PWD/opentelemetry-javaagent.jar -jar <my-app>.jar
```

- `<my-app>` is the name of your application jar file
- In case you download `opentelemetry-javaagent.jar` file in different directory than that of the project, replace `$PWD` with the path of the OTel jar file.

If your applications do not appear in the services section, please refer to the [troubleshooting section](#troubleshooting-your-installation).

</TabItem>
<TabItem value="k8s" label="Kubernetes">
You can auto-instrument sending traces from Java application using one of the following methods:

1. Using Kubernetes OTel Operator
2. Using OTel Collector Agent

<Tabs>
<TabItem value="k8s-otel-operator" label="K8s OTel Operator">

For a Java application deployed on Kubernetes, you can auto-instrument the traces using Kubernetes OpenTelemetry Operator.

An [OpenTelemetry Operator](https://opentelemetry.io/docs/kubernetes/operator) is a Kubernetes Operator that manages [OpenTelemetry Collectors](https://signoz.io/blog/opentelemetry-collector-complete-guide/) and auto-instrumentation of workloads. It simplifies the deployment and management of OpenTelemetry in a Kubernetes environment.

The OpenTelemetry Operator provides two Custom Resource Definitions (CRDs):

- `OpenTelemetryCollector`
- `Instrumentation`

The `OpenTelemetryCollector` CRD allows you to deploy and manage OpenTelemetry Collectors in your Kubernetes cluster.

The `Instrumentation` CRD allows you to configure and inject OpenTelemetry auto-instrumentation libraries into your workloads.

Here are the steps you need to follow to auto-instrument Java application using OTel Operator:

#### Step 1: Install cert-manager

Run the following commands to apply cert manager.

```bash
kubectl apply -f https://github.com/cert-manager/cert-manager/releases/download/v1.19.1/cert-manager.yaml

kubectl wait --for=condition=Available deployments/cert-manager -n cert-manager
```

#### Step 2: Install OpenTelemetry Operator

To install the operator in the existing K8s cluster, run the following command:

```bash
kubectl apply -f https://github.com/open-telemetry/opentelemetry-operator/releases/download/v0.139.0/opentelemetry-operator.yaml
```

Installing the OpenTelemetry Operator sets up the necessary components and configurations to enable the observability and monitoring of applications running in the cluster.

Verify operator is running:

```bash
kubectl get deployment opentelemetry-operator-controller-manager -n opentelemetry-operator-system
kubectl get pods -n opentelemetry-operator-system
```

#### Step 3: Setup the OpenTelemetry Collector instance

Once the `opentelemetry-operator` has been deployed, you can proceed with the creation of the OpenTelemetry Collector (`otelcol`) instance. The OpenTelemetry Collector collects, processes, and exports telemetry data.

There are different deployment modes for the `OpenTelemetryCollector`, and you can specify them in the spec.mode section of the custom resource. The available deployment modes are:

- [Daemonset](https://kubernetes.io/docs/concepts/workloads/controllers/daemonset/)
- [Sidecar](https://kubernetes.io/docs/concepts/workloads/pods/sidecar-containers/)
- [StatefulSet](https://kubernetes.io/docs/concepts/workloads/controllers/statefulset/)
- [Deployment](https://kubernetes.io/docs/concepts/workloads/controllers/deployment/) (default mode)

We will use the default `Deployment` mode here.

To create a simple instance of the OpenTelemetry Collector, create a file `otel-collector.yaml` with the following contents:

```yaml:otel-collector.yaml
apiVersion: opentelemetry.io/v1beta1
kind: OpenTelemetryCollector
metadata:
  name: otel
spec:
  mode: deployment
  config: |
    receivers:
      otlp:
        protocols:
          grpc:
            endpoint: 0.0.0.0:4317
          http:
            endpoint: 0.0.0.0:4318
    processors:
      batch: {}
      resource/env:
        attributes:
        - key: deployment.environment
          value: prod # can be dev, prod, staging etc. based on your environment
          action: upsert
    exporters:
      debug: {}
      otlp:
        endpoint: "ingest.<region>.signoz.cloud:443" # replace <region> with your region of SigNoz Cloud
        tls:
          insecure: false
        headers:
          "signoz-ingestion-key": "<your-ingestion-key>" # Obtain from https://{your-signoz-tenant-url}/settings/ingestion-settings
    service:
      pipelines:
        traces:
          receivers: [otlp]
          processors: [batch, resource/env]
          exporters: [otlp]
```

- Set the `<region>` to match your SigNoz Cloud [region](https://signoz.io/docs/ingestion/signoz-cloud/overview/#endpoint)
- Replace `<your-ingestion-key>` with your SigNoz [ingestion key](https://signoz.io/docs/ingestion/signoz-cloud/keys/)

Apply the above YAML file using the following command:

```bash
kubectl apply -f otel-collector.yaml
```

Verify OpenTelemetry Collector is running:

```bash
kubectl get opentelemetrycollector
kubectl get pods -l app.kubernetes.io/name=otel-collector
```

#### Step 4: Setup the Instrumentation instance

Once the OpenTelemetry Collector instance has been deployed, the next step is to create an instrumentation instance, which will be responsible for sending OTLP data to the OTel Collector.

Create a file `instrumentation.yaml` with the following contents:

```yaml:instrumentation.yaml
apiVersion: opentelemetry.io/v1alpha1
kind: Instrumentation
metadata:
  name: traces-instrumentation
spec:
  exporter:
    endpoint: http://otel-collector:4318
  env:
    - name: OTEL_EXPORTER_OTLP_PROTOCOL
      value: "http/protobuf"
    - name: OTEL_EXPORTER_OTLP_INSECURE
      value: "true"
  propagators:
    - tracecontext
    - baggage
    - b3
  sampler:
    type: parentbased_traceidratio
    argument: "1"
  java:
    image: ghcr.io/open-telemetry/opentelemetry-operator/autoinstrumentation-java:latest
```

Apply the above instrumentation using the following command:

```bash
kubectl apply -f instrumentation.yaml
```

#### Step 5: Auto-instrument your Java app with OpenTelemetry

Create `deployment.yaml` file for your Java application as follows:

```yaml:deployment.yaml
apiVersion: apps/v1
kind: Deployment
metadata:
  name: java-app
spec:
  selector:
    matchLabels:
      app: java-app
  replicas: 1
  template:
    metadata:
      labels:
        app: java-app
      annotations:
        instrumentation.opentelemetry.io/inject-java: "true"
        resource.opentelemetry.io/service.name: "java-app"
    spec:
      containers:
      - name: app
        image: java-app:latest
        ports:
        - containerPort: 8080
```

It is important to add the following annotation under `spec > template > metadata > annotations`:

```
instrumentation.opentelemetry.io/inject-java: "true"
```

This helps in auto-instrumenting the traces from the Java application.

Apply the deployment using the following command:

```bash
kubectl apply -f deployment.yaml
```

With this, the auto-instrumentation of traces for Java application is ready.

#### Step 6: Running the Java application

In order to run the application on port 8080, run the following commands:

```bash
export POD_NAME=$(kubectl get pod -l app=java-app -o jsonpath="{.items[0].metadata.name}")  # Adjust 'java-app' to match your app label if different.

kubectl port-forward ${POD_NAME} 8080:8080
```

You can now access the application on port 8080.

You can validate if your application is sending traces to SigNoz cloud by following the instructions [here](#validating-instrumentation-by-checking-for-traces).

</TabItem>
<TabItem value="otel-collector-agent" label="OTel Collector Agent" default>

For a Java application deployed on Kubernetes, you need to install OTel Collector agent in your k8s infra to collect and send traces to SigNoz Cloud.

**Step 1. Install OTel Collector Agent**

Add the SigNoz Helm repository:

```bash
helm repo add signoz https://charts.signoz.io
helm repo update
```

Install the chart with your SigNoz Cloud configuration:

```bash
helm install k8s-infra signoz/k8s-infra \
  --set otelCollectorEndpoint=ingest.<region>.signoz.cloud:443 \
  --set otelCollectorHeader.signoz-ingestion-key=<your-ingestion-key> \
  --set global.clusterName=<your-cluster-name>
```

- Set the `<region>` to match your SigNoz Cloud [region](https://signoz.io/docs/ingestion/signoz-cloud/overview/#endpoint)
- Replace `<your-ingestion-key>` with your SigNoz [ingestion key](https://signoz.io/docs/ingestion/signoz-cloud/keys/)
- Replace `<your-cluster-name>` with a name for your Kubernetes cluster

Once you have set up OTel Collector agent, you can proceed with OpenTelemetry Java instrumentation by following the below steps:

**Step 1. Download OTel Java binary agent**

```bash
wget https://github.com/open-telemetry/opentelemetry-java-instrumentation/releases/latest/download/opentelemetry-javaagent.jar
```

**Step 2. Run your application in Kubernetes**

For Kubernetes deployments, you need to containerize your Java application with the OpenTelemetry Java agent.

**Step 2.1: Create a Dockerfile for your Java application**

Create a `Dockerfile` in your application's root directory. This `Dockerfile` will:

- Build your Java application.
- Download the OpenTelemetry Java agent.
- Package both into a Docker image.

```dockerfile
# Use a base image with Java installed
FROM eclipse-temurin:17-jre

# Set working directory
WORKDIR /app

# Copy your application's JAR file
COPY target/<my-app>.jar app.jar

# Download the OpenTelemetry Java agent
RUN wget https://github.com/open-telemetry/opentelemetry-java-instrumentation/releases/latest/download/opentelemetry-javaagent.jar -O opentelemetry-javaagent.jar

# Command to run the application with the OpenTelemetry agent
ENTRYPOINT ["java", "-javaagent:/app/opentelemetry-javaagent.jar", "-jar", "app.jar"]
```

- Replace `<my-app>.jar` with the actual name of your application's JAR file.

**Step 2.2: Build and push your Docker image**

Build your Docker image and push it to a container registry (e.g., Docker Hub, GCR, ECR).

```bash
docker build -t <your-registry>/<your-app-image-name>:<tag> .
docker push <your-registry>/<your-app-image-name>:<tag>
```

**Step 2.3: Deploy your application to Kubernetes**

Create a Kubernetes Deployment YAML file (e.g., `java-app-deployment.yaml`) to deploy your containerized application. This example assumes you have an OpenTelemetry Collector running as a `Service` named `otel-collector` in the `default` namespace and listening on port `4317` for OTLP/gRPC.

```yaml
apiVersion: apps/v1
kind: Deployment
metadata:
  name: <your-java-app-name>
  labels:
    app: <your-java-app-name>
spec:
  replicas: 1
  selector:
    matchLabels:
      app: <your-java-app-name>
  template:
    metadata:
      labels:
        app: <your-java-app-name>
    spec:
      containers:
        - name: <your-java-app-name>
          image: <your-registry>/<your-app-image-name>:<tag> # Replace with your image
          ports:
            - containerPort: 8080 # Adjust to your application's port
          env:
            - name: OTEL_RESOURCE_ATTRIBUTES
              value: service.name=<your-service-name> # Name of your service
            - name: OTEL_EXPORTER_OTLP_ENDPOINT
              value: http://otel-collector:4317 # Point to your OTel Collector service
            - name: OTEL_EXPORTER_OTLP_PROTOCOL
              value: grpc
          # Optional: If your application needs to listen on a specific port
          # - name: SERVER_PORT
          #   value: "8080"
```

- Replace `<your-java-app-name>`, `<your-registry>/<your-app-image-name>:<tag>`, and `<your-service-name>` with your specific values.
- Adjust `containerPort` if your application listens on a different port.
- The `OTEL_EXPORTER_OTLP_ENDPOINT` assumes your OpenTelemetry Collector is accessible via `http://otel-collector:4317`. Adjust this if your collector service name or port is different.

Apply the deployment:

```bash
kubectl apply -f java-app-deployment.yaml
```

You can validate if your application is sending traces to SigNoz cloud by following the instructions [here](#validating-instrumentation-by-checking-for-traces).

If your applications do not appear in the services section, please refer to the [troubleshooting section](#troubleshooting-your-installation).

</TabItem>
</Tabs>

</TabItem>
<TabItem value="Docker" label="Docker">

There are two ways to send data to SigNoz Cloud. You can containerize the images in both the cases.

- [Send traces directly to SigNoz Cloud](#send-traces-directly-to-signoz-cloud-1)
- [Send traces via OTel Collector binary](#send-traces-via-otel-collector-binary-1) (recommended)

#### Send traces directly to SigNoz Cloud

**Step 1. Configure OpenTelemetry to run in Docker Container**

Add the following in your Dockerfile.

```dockerfile
...

# Download OpenTelemetry Java Agent
RUN wget -O opentelemetry-javaagent.jar \
    https://github.com/open-telemetry/opentelemetry-java-instrumentation/releases/latest/download/opentelemetry-javaagent.jar

...

# Set environment variables for OTEL
ENV OTEL_RESOURCE_ATTRIBUTES="service.name=<service_name>"
ENV OTEL_EXPORTER_OTLP_HEADERS="signoz-ingestion-key=<your-ingestion-key>"
ENV OTEL_EXPORTER_OTLP_ENDPOINT="https://ingest.<region>.signoz.cloud:443"

...

# Run the application with instrumentation
ENTRYPOINT ["java", "-javaagent:/opentelemetry-javaagent.jar", "-jar", "app.jar"]
```

- Set the `<region>` to match your SigNoz Cloud [region](https://signoz.io/docs/ingestion/signoz-cloud/overview/#endpoint)
- Replace `<your-ingestion-key>` with your SigNoz [ingestion key](https://signoz.io/docs/ingestion/signoz-cloud/keys/)
- `<service_name>` is name of your service

The above steps install OpenTelemetry dependencies directly inside the Docker container & sets environment variables to export the traces.

**Step 2. Run your Docker container**

Here's how you can run your docker container:

```bash
docker build -t <image-name> . && docker run -d -p <host-port>:<container-port> <image-name>
```

- Replace `<image-name>`, `<host-port>`, and `<container-port>` with values for your application.

- `-d` runs the container in detached mode
- `-p` maps a host port to a container port

**Step 3.** Validate if your application is sending traces to SigNoz cloud by following the instructions [here](#validating-instrumentation-by-checking-for-traces).

If your applications do not appear in the services section, please refer to the [troubleshooting section](#troubleshooting-your-installation).

---

#### Send traces via OTel Collector binary

**Step 1. Configure OpenTelemetry Collector to run in Docker Container**

Add the following in your Dockerfile.

```dockerfile
# -------- Stage 1: Get OpenTelemetry Collector --------
FROM otel/opentelemetry-collector-contrib:0.139.0 AS otel

...

# Download OpenTelemetry Java Agent
RUN wget -O opentelemetry-javaagent.jar \
    https://github.com/open-telemetry/opentelemetry-java-instrumentation/releases/latest/download/opentelemetry-javaagent.jar

...

# Copy OpenTelemetry Collector binary + config from first stage
COPY --from=otel /otelcol-contrib /otelcol-contrib
COPY --from=otel /etc/otelcol-contrib /etc/otelcol-contrib
COPY config.yaml /etc/otelcol-contrib/config.yaml

# Expose ports (App + Collector)
EXPOSE <APP_PORT> 4317 4318

...

# Environment variables (point Java to local Collector)
ENV OTEL_SERVICE_NAME="<service_name>"
ENV OTEL_TRACES_EXPORTER="otlp"
ENV OTEL_EXPORTER_OTLP_PROTOCOL="http/protobuf"
ENV OTEL_EXPORTER_OTLP_ENDPOINT="http://localhost:4318"
ENV OTEL_PROPAGATORS="baggage,tracecontext"


# Run both Collector and Java app in the same container
CMD sh -c "/otelcol-contrib --config=/etc/otelcol-contrib/config.yaml & \
    java -javaagent:/opentelemetry-javaagent.jar -jar /app/app.jar"
```

Make sure you have `config.yaml` in `root` of the application. This `config.yaml` should be copied from third step of [this](https://signoz.io/docs/collection-agents/docker/install/#step-2-create-collector-configuration)

- `<service_name>` is name of your service

**Step 2. Run your Docker container**

Run your docker container to start exporting.

```bash
docker build -t <image-name> . && docker run -d -p <host-port>:<container-port> <image-name>
```

- Replace `<image-name>`, `<host-port>`, and `<container-port>` with values for your application.

- `-d` runs the container in detached mode

- `-p` maps a host port to a container port

**Step 3.** You can validate if your application is sending traces to SigNoz cloud by following the instructions [here](#validating-instrumentation-by-checking-for-traces).

If your applications do not appear in the services section, please refer to the [troubleshooting section](#troubleshooting-your-installation).

</TabItem>

</Tabs>
<TabItem value='self-host' label='Self-Host'>

## Send Traces to Self-Hosted SigNoz

You can use OpenTelemetry Java to send your traces directly to SigNoz. OpenTelemetry provides a **Java JAR agent** that can be attached to any Java 8+ application and dynamically injects bytecode to capture telemetry from a number of popular libraries and frameworks.

### Steps to auto-instrument Java applications for traces

[OpenTelemetry Java auto-instrumentation](https://signoz.io/opentelemetry/java-auto-instrumentation/) supports collecting telemetry data from a huge number of libraries and frameworks. You can check out the full list [here](https://github.com/open-telemetry/opentelemetry-java-instrumentation/blob/main/docs/supported-libraries.md).

**Step 1. Download the latest OpenTelemetry Java JAR agent**

Download the latest [Java JAR agent](https://github.com/open-telemetry/opentelemetry-java-instrumentation/releases/latest/download/opentelemetry-javaagent.jar). You can also use the terminal to get the file using the following command:

```bash
wget https://github.com/open-telemetry/opentelemetry-java-instrumentation/releases/latest/download/opentelemetry-javaagent.jar
```

**Step 2. Enable the instrumentation agent and run your application**

If you run your Java application as a JAR file, run your application using the following command:

```bash
OTEL_EXPORTER_OTLP_ENDPOINT="http://<IP of SigNoz Backend>:4317" OTEL_RESOURCE_ATTRIBUTES=service.name=<app-name> java -javaagent:/path/to/opentelemetry-javaagent.jar -jar  <my-app>.jar
```

where `<app-name>` is the name you want to set for your application. `path` should be updated to the path of the downloaded Java JAR agent.

In the above command, we are configuring the exporter to send data to SigNoz backend. By default, OpenTelemetry Java agent uses [OTLP exporter](https://github.com/open-telemetry/opentelemetry-java/tree/main/exporters/otlp) configured to send data.

Two things to note about the command:

`OTEL_EXPORTER_OTLP_ENDPOINT` - This is the endpoint of the machine where SigNoz is installed.

`path/to` - Update it to the path of your downloaded Java JAR agent.

If you have installed SigNoz on your `localhost` and your Java JAR agent is saved at `/Users/john/Downloads/`, then the final command looks like:

```bash
OTEL_EXPORTER_OTLP_ENDPOINT="http://localhost:4317" OTEL_RESOURCE_ATTRIBUTES=service.name=javaApp java -javaagent:/Users/john/Downloads/opentelemetry-javaagent.jar -jar target/*.jar
```

Here's a handy [grid](https://signoz.io/docs/instrumentation/troubleshoot-instrumentation/) to figure out which address to use to send data to SigNoz.

You can also specify environment variables in the following way:

```bash
java -javaagent:/path/opentelemetry-javaagent.jar \
    -Dotel.exporter.otlp.endpoint=http://<IP of SigNoz Backend>:4317 \
    -Dotel.resource.attributes=service.name=<app-name> \
    -jar <my-app>.jar
```

<Admonition>
  ðŸ’¡ Remember to allow incoming requests to port 4317 of the machine where SigNoz backend is hosted.
</Admonition>

If your applications do not appear in the services section, please refer to the [troubleshooting section](#troubleshooting-your-installation).

</TabItem>
</TabItem>
</Tabs>

**Note:** By default, Java auto-instrumentation does not create spans for user-defined functions. In such scenarios, we can use annotations to quickly create spans for user-defined functions with minimal code change. You can instrument your Java application following this [guide on annotations](https://signoz.io/docs/instrumentation/manual-instrumentation/java/annotations/).

## Validating instrumentation by checking for traces

With your application running, you can verify that you've instrumented your application with OpenTelemetry correctly by confirming that tracing data is being reported to SigNoz.

To do this, you need to ensure that your application generates some data. Applications will not produce traces unless they are being interacted with, and OpenTelemetry will often buffer data before sending. So you need to interact with your application and wait for some time to see your tracing data in SigNoz.

Validate your traces in SigNoz:

1. Trigger an action in your app that generates a web request. Hit the endpoint a number of times to generate some data. Then, wait for some time.
2. In SigNoz, open the `Services` tab. Hit the `Refresh` button on the top right corner, and your application should appear in the list of `Applications`. Ensure that you're checking data for the `time range filter` applied in the top right corner.
3. Go to the `Traces` tab, and apply relevant filters to see your application's traces.

## Configuring the agent

The agent is highly configurable. You can check out all the configuration options available [here](https://opentelemetry.io/docs/instrumentation/java/automatic/agent-config/).

## Disabled instrumentations

Some instrumentations can produce too many spans and make traces very noisy. For this reason, the following instrumentations are disabled by default:

- `jdbc-datasource` which creates spans whenever the `java.sql.DataSource#getConnection` method is called.
- `dropwizard-metrics`, which might create very low-quality metrics data because of the lack of label/attribute support in the Dropwizard metrics API.

To enable them, add the `otel.instrumentation.<name>.enabled` system property: `-Dotel.instrumentation.jdbc-datasource.enabled=true`

## Manual Instrumentation

For manual instrumentation of Java application, refer to the docs [here](https://opentelemetry.io/docs/instrumentation/java/manual/).

## Troubleshooting your installation

If spans are not being reported to SigNoz, try running in debug mode by setting `OTEL_LOG_LEVEL=debug`:

The debug log level will print out the configuration information. It will also emit every span to the console, which should look something like:

```code
Span #0
    Trace ID       : eed0cb58866c16e8b363500731d91254
    Parent ID      :
    ID             : b5dd3686f3c6cd1d
    Name           : GET /hello
    Kind           : Server
    Start time     : 2025-11-19 16:18:07.316959644 +0000 UTC
    End time       : 2025-11-19 16:18:07.414811578 +0000 UTC
    Status code    : Unset
    Status message :
Attributes:
    -> http.request.method: Str(GET)
    -> server.port: Int(8080)
    -> http.route: Str(/hello)
    -> server.address: Str(localhost)
    -> client.address: Str(127.0.0.1)
    -> thread.id: Int(32)
    -> network.peer.address: Str(127.0.0.1)
    -> url.path: Str(/hello)
    -> http.response.status_code: Int(200)
    -> url.scheme: Str(http)
    -> thread.name: Str(http-nio-8080-exec-7)
    -> network.protocol.version: Str(1.1)
    -> network.peer.port: Int(60666)
    -> user_agent.original: Str(curl/8.7.1)
```

## Sample Java Application

- We have included a sample Java application with README.md at [Sample Java App Github Repo.](https://github.com/SigNoz/distributed-tracing-java-sample)

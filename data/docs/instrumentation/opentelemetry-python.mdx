---
date: 2026-01-17
id: python

title: Python OpenTelemetry Instrumentation
description: Send traces to SigNoz using OpenTelemetry instrumentation for Python frameworks like Django, Flask, FastAPI, and Celery.
doc_type: howto
---

This guide shows you how to instrument your Python application with OpenTelemetry and send traces to SigNoz. The auto-instrumentation approach works with Django, Flask, FastAPI, Falcon, Celery, and most Python libraries out of the box.

<KeyPointCallout title="Using self-hosted SigNoz?" defaultCollapsed="true">
Most steps are identical. To adapt this guide, update the endpoint and remove the ingestion key header as shown in [Cloud → Self-Hosted](https://signoz.io/docs/ingestion/cloud-vs-self-hosted/#cloud-to-self-hosted).
</KeyPointCallout>

## Prerequisites

- Python 3.8 or newer
- A SigNoz Cloud account or self-hosted SigNoz instance

Tested with Python 3.11 and OpenTelemetry Python SDK v1.27.0.

## Send traces to SigNoz

<Tabs entityName="deployment">
<TabItem value="vm" label="VM" default>

<KeyPointCallout title="What classifies as VM?" defaultCollapsed="true">
A VM is a virtual computer that runs on physical hardware. This includes:
- **Cloud VMs**: AWS EC2, Google Compute Engine, Azure VMs, DigitalOcean Droplets
- **On-premise VMs**: VMware, VirtualBox, Hyper-V, KVM
- **Bare metal servers**: Physical servers running Linux/Unix directly

Use this section if you're deploying your Python application directly on a server or VM without containerization.
</KeyPointCallout>

### Step 1. Set environment variables

```bash
export OTEL_RESOURCE_ATTRIBUTES="service.name=<service-name>"
export OTEL_EXPORTER_OTLP_ENDPOINT="https://ingest.<region>.signoz.cloud:443"
export OTEL_EXPORTER_OTLP_HEADERS="signoz-ingestion-key=<your-ingestion-key>"
export OTEL_EXPORTER_OTLP_PROTOCOL="grpc"
export OTEL_METRICS_EXPORTER="none"
```

<KeyPointCallout title="Why explicitly disable metrics?" defaultCollapsed="true">
The bootstrap command (Step 3) installs instrumentations for all detected libraries, including HTTP clients like `requests`, `urllib3`, and `httpx`. These libraries generate metrics such as request duration histograms and optionally request/response body sizes for every outgoing HTTP call.

Since `opentelemetry-distro` enables metrics by default, these HTTP metrics would be sent to SigNoz even though this guide only covers traces. For apps that make frequent HTTP calls, this can add up quickly.

Setting this to `none` disables metrics while keeping traces working as expected. If you want metrics later, you can change it to `otlp` or remove this variable altogether.
</KeyPointCallout>

Verify these values:
- `<region>`: Your [SigNoz Cloud region](https://signoz.io/docs/ingestion/signoz-cloud/overview/#endpoint)
- `<your-ingestion-key>`: Your SigNoz [ingestion key](https://signoz.io/docs/ingestion/signoz-cloud/keys/).
- `<service-name>`: A descriptive name for your service (e.g., `payment-service`).

### Step 2. Install OpenTelemetry packages

```bash
pip install opentelemetry-distro opentelemetry-exporter-otlp
```

### Step 3. Install instrumentation for your dependencies

This command detects your installed packages and adds the corresponding instrumentation libraries:

```bash
opentelemetry-bootstrap --action=install
```

<Admonition type="info">
Run this after installing all your application dependencies. It will only instrument packages that are already installed.
</Admonition>

### Step 4. Run your application

```bash
opentelemetry-instrument <your_run_command>
```

See [Framework instrumentation](#framework-instrumentation) below for framework-specific commands.

</TabItem>
<TabItem value="k8s" label="Kubernetes">

<Tabs entityName="k8s-method">
<TabItem value="direct" label="Direct" default>

<KeyPointCallout title="Managing multiple services?" defaultCollapsed="true">
For centralized instrumentation management or auto-injection without code changes, see the OTel Operator tab.
</KeyPointCallout>

### Step 1. Set environment variables

Add these environment variables to your deployment manifest:

```yaml
env:
- name: OTEL_RESOURCE_ATTRIBUTES
  value: 'service.name=<service-name>'
- name: OTEL_EXPORTER_OTLP_ENDPOINT
  value: 'https://ingest.<region>.signoz.cloud:443'
- name: OTEL_EXPORTER_OTLP_HEADERS
  value: 'signoz-ingestion-key=<your-ingestion-key>'
- name: OTEL_EXPORTER_OTLP_PROTOCOL
  value: 'grpc'
- name: OTEL_METRICS_EXPORTER
  value: 'none'
```

<KeyPointCallout title="Why explicitly disable metrics?" defaultCollapsed="true">
The bootstrap command (Step 3) installs instrumentations for all detected libraries, including HTTP clients like `requests`, `urllib3`, and `httpx`. These libraries generate metrics such as request duration histograms and optionally request/response body sizes for every outgoing HTTP call.

Since `opentelemetry-distro` enables metrics by default, these HTTP metrics would be sent to SigNoz even though this guide only covers traces. For apps that make frequent HTTP calls, this can add up quickly.

Setting this to `none` disables metrics while keeping traces working as expected. If you want metrics later, you can change it to `otlp` or remove this variable altogether.
</KeyPointCallout>

Verify these values:
- `<region>`: Your [SigNoz Cloud region](https://signoz.io/docs/ingestion/signoz-cloud/overview/#endpoint)
- `<your-ingestion-key>`: Your SigNoz [ingestion key](https://signoz.io/docs/ingestion/signoz-cloud/keys/).
- `<service-name>`: A descriptive name for your service (e.g., `payment-service`).

### Step 2. Install OpenTelemetry packages

```bash
pip install opentelemetry-distro opentelemetry-exporter-otlp
```

### Step 3. Install instrumentation for your dependencies

This command detects your installed packages and adds the corresponding instrumentation libraries:

```bash
opentelemetry-bootstrap --action=install
```

<Admonition type="info">
Run this after installing all your application dependencies. It will only instrument packages that are already installed.
</Admonition>

### Step 4. Run your application

```bash
opentelemetry-instrument <your_run_command>
```

See [Framework instrumentation](#framework-instrumentation) below for framework-specific commands.

</TabItem>
<TabItem value="otel-operator" label="OTel Operator">

The [OpenTelemetry Operator](https://signoz.io/docs/opentelemetry-collection-agents/k8s/otel-operator/overview/) auto-injects instrumentation into your Python pods without modifying your application image.

### Step 1. Set up the OpenTelemetry Operator

Install the Operator and Collector following the [K8s OTel Operator installation guide](https://signoz.io/docs/opentelemetry-collection-agents/k8s/otel-operator/install/).

### Step 2. Create the Instrumentation resource

Create `instrumentation.yaml` to configure Python auto-instrumentation:

```yaml:instrumentation.yaml
apiVersion: opentelemetry.io/v1alpha1
kind: Instrumentation
metadata:
  name: python-instrumentation
spec:
  exporter:
    endpoint: http://otel-collector-collector:4318
  propagators:
    - tracecontext
    - baggage
  env:
    - name: OTEL_METRICS_EXPORTER
      value: "none"
  python:
    image: ghcr.io/open-telemetry/opentelemetry-operator/autoinstrumentation-python:latest
```

<KeyPointCallout title="Why explicitly disable metrics?" defaultCollapsed="true">
The OTel Operator's Python auto-instrumentation image includes instrumentations for HTTP clients like `requests`, `urllib3`, and `httpx`. These libraries generate metrics such as request duration histograms for every outgoing HTTP call.

Since metrics are enabled by default, these HTTP metrics would be sent to your collector even though this guide only covers traces. For apps that make frequent HTTP calls, this can add up quickly.

Setting `OTEL_METRICS_EXPORTER` to `none` disables metrics while keeping traces working as expected. If you want metrics later, you can change it to `otlp` or remove this variable altogether.
</KeyPointCallout>

Deploy this resource to your cluster.

### Step 3. Add annotations to your deployment

Add these annotations to your pod template's `metadata.annotations`:

```yaml
instrumentation.opentelemetry.io/inject-python: "true"
instrumentation.opentelemetry.io/otel-python-platform: "glibc"  # or "musl" for Alpine
```

</TabItem>
</Tabs>

</TabItem>
<TabItem value="windows" label="Windows">

### Step 1. Set environment variables

```powershell
$env:OTEL_RESOURCE_ATTRIBUTES = "service.name=<service-name>"
$env:OTEL_EXPORTER_OTLP_ENDPOINT = "https://ingest.<region>.signoz.cloud:443"
$env:OTEL_EXPORTER_OTLP_HEADERS = "signoz-ingestion-key=<your-ingestion-key>"
$env:OTEL_EXPORTER_OTLP_PROTOCOL = "grpc"
$env:OTEL_METRICS_EXPORTER = "none"
```

<KeyPointCallout title="Why explicitly disable metrics?" defaultCollapsed="true">
The bootstrap command (Step 3) installs instrumentations for all detected libraries, including HTTP clients like `requests`, `urllib3`, and `httpx`. These libraries generate metrics such as request duration histograms and optionally request/response body sizes for every outgoing HTTP call.

Since `opentelemetry-distro` enables metrics by default, these HTTP metrics would be sent to SigNoz even though this guide only covers traces. For apps that make frequent HTTP calls, this can add up quickly.

Setting this to `none` disables metrics while keeping traces working as expected. If you want metrics later, you can change it to `otlp` or remove this variable altogether.
</KeyPointCallout>

Verify these values:
- `<region>`: Your [SigNoz Cloud region](https://signoz.io/docs/ingestion/signoz-cloud/overview/#endpoint)
- `<your-ingestion-key>`: Your SigNoz [ingestion key](https://signoz.io/docs/ingestion/signoz-cloud/keys/).
- `<service-name>`: A descriptive name for your service (e.g., `payment-service`).

### Step 2. Install OpenTelemetry packages

```bash
pip install opentelemetry-distro opentelemetry-exporter-otlp
```

### Step 3. Install instrumentation for your dependencies

This command detects your installed packages and adds the corresponding instrumentation libraries:

```bash
opentelemetry-bootstrap --action=install
```

<Admonition type="info">
Run this after installing all your application dependencies. It will only instrument packages that are already installed.
</Admonition>

### Step 4. Run your application

```bash
opentelemetry-instrument <your_run_command>
```

See [Framework instrumentation](#framework-instrumentation) below for framework-specific commands.

</TabItem>
<TabItem value="docker" label="Docker">

### Step 1. Set environment variables in Dockerfile

```dockerfile
ENV OTEL_RESOURCE_ATTRIBUTES=service.name=<service-name>
ENV OTEL_EXPORTER_OTLP_ENDPOINT=https://ingest.<region>.signoz.cloud:443
ENV OTEL_EXPORTER_OTLP_HEADERS=signoz-ingestion-key=<your-ingestion-key>
ENV OTEL_EXPORTER_OTLP_PROTOCOL=grpc
ENV OTEL_METRICS_EXPORTER=none
```

Or pass them at runtime using `docker run`:

```bash
docker run -e OTEL_RESOURCE_ATTRIBUTES="service.name=<service-name>" \
    -e OTEL_EXPORTER_OTLP_ENDPOINT="https://ingest.<region>.signoz.cloud:443" \
    -e OTEL_EXPORTER_OTLP_HEADERS="signoz-ingestion-key=<your-ingestion-key>" \
    -e OTEL_EXPORTER_OTLP_PROTOCOL="grpc" \
    -e OTEL_METRICS_EXPORTER="none" \
    your-image:latest
```

<KeyPointCallout title="Why explicitly disable metrics?" defaultCollapsed="true">
The bootstrap command (Step 3) installs instrumentations for all detected libraries, including HTTP clients like `requests`, `urllib3`, and `httpx`. These libraries generate metrics such as request duration histograms and optionally request/response body sizes for every outgoing HTTP call.

Since `opentelemetry-distro` enables metrics by default, these HTTP metrics would be sent to SigNoz even though this guide only covers traces. For apps that make frequent HTTP calls, this can add up quickly.

Setting this to `none` disables metrics while keeping traces working as expected. If you want metrics later, you can change it to `otlp` or remove this variable altogether.
</KeyPointCallout>

Verify these values:
- `<region>`: Your [SigNoz Cloud region](https://signoz.io/docs/ingestion/signoz-cloud/overview/#endpoint)
- `<your-ingestion-key>`: Your SigNoz [ingestion key](https://signoz.io/docs/ingestion/signoz-cloud/keys/).
- `<service-name>`: A descriptive name for your service (e.g., `payment-service`).

### Step 2. Install OpenTelemetry packages

```bash
pip install opentelemetry-distro opentelemetry-exporter-otlp
```

### Step 3. Install instrumentation for your dependencies

This command detects your installed packages and adds the corresponding instrumentation libraries:

```bash
opentelemetry-bootstrap --action=install
```

<Admonition type="info">
Run this after installing all your application dependencies. It will only instrument packages that are already installed.
</Admonition>

### Step 4. Run your application

```bash
opentelemetry-instrument <your_run_command>
```

See [Framework instrumentation](#framework-instrumentation) below for framework-specific commands.

</TabItem>
</Tabs>

## Framework instrumentation

Choose your framework below to see the specific run command. The setup steps above are the same for all frameworks.

<LibraryTabs
    className="mb-8"
    defaultCategory="all"
    defaultLibrary="django"
    categoryLabels={{
        web: 'Web Frameworks',
        worker: 'Background Workers',
    }}
>
    <LibraryTab value="django" label="Django" category="web">

        ### Prerequisites

        Set the `DJANGO_SETTINGS_MODULE` environment variable:

        ```bash
        export DJANGO_SETTINGS_MODULE=myproject.settings
        ```

        ### Run command

        ```bash
        opentelemetry-instrument python manage.py runserver --noreload
        ```

        <Admonition type="warning">
        Always use `--noreload` with Django. The auto-reload mechanism spawns child processes that break OpenTelemetry instrumentation.
        </Admonition>

        <KeyPointCallout title="For Docker users" defaultCollapsed="true">
        ```dockerfile
        CMD ["opentelemetry-instrument", "python", "manage.py", "runserver", "0.0.0.0:8000", "--noreload"]
        ```
        </KeyPointCallout>

    </LibraryTab>
    <LibraryTab value="flask" label="Flask" category="web">

        ### Run command

        ```bash
        opentelemetry-instrument flask run --no-reload
        ```

        Or if running directly:

        ```bash
        opentelemetry-instrument python app.py
        ```

        <Admonition type="warning">
        Always use `--no-reload` with Flask. The reloader spawns a child process that breaks OpenTelemetry instrumentation. Also avoid `FLASK_ENV=development` as it enables the reloader.
        </Admonition>

        <KeyPointCallout title="For Docker users" defaultCollapsed="true">
        ```dockerfile
        CMD ["opentelemetry-instrument", "flask", "run", "--host=0.0.0.0", "--no-reload"]
        ```

        Or:

        ```dockerfile
        CMD ["opentelemetry-instrument", "python", "app.py"]
        ```
        </KeyPointCallout>

    </LibraryTab>
    <LibraryTab value="fastapi" label="FastAPI" category="web">

        ### Run command

        ```bash
        opentelemetry-instrument uvicorn main:app --host 0.0.0.0 --port 8000
        ```

        <Admonition type="warning">
        Do not use `--reload` with Uvicorn when instrumenting. The reload mode spawns new processes that break instrumentation.
        </Admonition>

        <Admonition type="info">
        Uvicorn's `--workers` flag is not supported with `opentelemetry-instrument`. Use Gunicorn with Uvicorn workers instead: `gunicorn -k uvicorn.workers.UvicornWorker main:app`
        </Admonition>

        <KeyPointCallout title="For Docker users" defaultCollapsed="true">
        ```dockerfile
        CMD ["opentelemetry-instrument", "uvicorn", "main:app", "--host", "0.0.0.0", "--port", "8000"]
        ```
        </KeyPointCallout>

    </LibraryTab>
    <LibraryTab value="falcon" label="Falcon" category="web">

        ### Run command (with Gunicorn)

        ```bash
        opentelemetry-instrument gunicorn app:api --bind 0.0.0.0:8000
        ```

        Or with Waitress:

        ```bash
        opentelemetry-instrument waitress-serve --port=8000 app:api
        ```

        <KeyPointCallout title="For Docker users" defaultCollapsed="true">
        ```dockerfile
        CMD ["opentelemetry-instrument", "gunicorn", "app:api", "--bind", "0.0.0.0:8000"]
        ```
        </KeyPointCallout>

    </LibraryTab>
    <LibraryTab value="celery" label="Celery" category="worker">

        ### Run command

        ```bash
        opentelemetry-instrument celery -A tasks worker --loglevel=info
        ```

        Replace `tasks` with your Celery app module name.

        <KeyPointCallout title="For Docker users" defaultCollapsed="true">
        ```dockerfile
        CMD ["opentelemetry-instrument", "celery", "-A", "tasks", "worker", "--loglevel=info"]
        ```
        </KeyPointCallout>

        <Admonition type="info">
        Celery instrumentation captures task execution spans, including task name, arguments, and status. Both the worker and the code that enqueues tasks should be instrumented for full trace propagation.
        </Admonition>

        <KeyPointCallout title="Celery with prefork workers (advanced)" defaultCollapsed="true">
        Celery uses the prefork worker model by default. The OpenTelemetry SDK is not fork-safe, so you must initialize it in each worker process using the `worker_process_init` signal. Add this to your Celery app file:

        ```python
        from celery.signals import worker_process_init
        from opentelemetry.instrumentation.celery import CeleryInstrumentor
        from opentelemetry import trace
        from opentelemetry.exporter.otlp.proto.grpc.trace_exporter import OTLPSpanExporter
        from opentelemetry.sdk.resources import Resource
        from opentelemetry.sdk.trace import TracerProvider
        from opentelemetry.sdk.trace.export import BatchSpanProcessor

        @worker_process_init.connect(weak=False)
        def init_celery_tracing(*args, **kwargs):
            CeleryInstrumentor().instrument()
            resource = Resource.create({})
            trace.set_tracer_provider(TracerProvider(resource=resource))
            span_processor = BatchSpanProcessor(OTLPSpanExporter())
            trace.get_tracer_provider().add_span_processor(span_processor)
        ```

        This ensures each worker process creates its own tracer instance. Only required for workers, not for the code that enqueues tasks.
        </KeyPointCallout>

    </LibraryTab>
    <LibraryTab value="hypercorn-unicorn" label="Hypercorn/Unicorn" category="web">

        <Admonition type="warning">
        **Hypercorn** and **Unicorn** are **not supported** by OpenTelemetry auto-instrumentation due to fork-safety limitations.
        </Admonition>

        ### Why they don't work

        The OpenTelemetry SDK components (`BatchSpanProcessor`, `PeriodicExportingMetricReader`, `BatchLogProcessor`) spawn background threads and use locks, which are not fork-safe (see <a href="https://bugs.python.org/issue6721" target="_blank" rel="noopener noreferrer nofollow">Python issue #6721</a>).

        Most ASGI servers work around this using `register_at_fork` hooks to reinitialize after forking. However, Hypercorn and Unicorn use the `spawn` method to start worker processes, which doesn't invoke these hooks—making the workaround ineffective.

        ### Recommended alternative

        Use Gunicorn with Uvicorn workers instead:

        ```bash
        opentelemetry-instrument gunicorn -k uvicorn.workers.UvicornWorker main:app --bind 0.0.0.0:8000
        ```

        <KeyPointCallout title="For Docker users" defaultCollapsed="true">
        ```dockerfile
        CMD ["opentelemetry-instrument", "gunicorn", "-k", "uvicorn.workers.UvicornWorker", "main:app", "--bind", "0.0.0.0:8000"]
        ```
        </KeyPointCallout>

        This gives you the same ASGI capabilities with proper OpenTelemetry support. See <a href="https://github.com/pgjones/hypercorn/issues/215" target="_blank" rel="noopener noreferrer nofollow">this issue</a> for updates on native Hypercorn support.

    </LibraryTab>
</LibraryTabs>

<details>
<ToggleHeading>

## Running with Gunicorn or uWSGI

</ToggleHeading>

**Gunicorn** works out of the box. No extra setup needed unless you use the `--preload` flag. If you do use `--preload`, see the <a href="https://github.com/open-telemetry/opentelemetry-python/tree/main/docs/examples/fork-process-model" target="_blank" rel="noopener noreferrer nofollow">post_fork hook example</a>.

**uWSGI** requires one of these options:
- Add `lazy-apps = true` to your uWSGI config (recommended, simplest fix)
- Or implement a post_fork hook (see <a href="https://opentelemetry-python.readthedocs.io/en/latest/examples/fork-process-model/README.html" target="_blank" rel="noopener noreferrer nofollow">example</a>)

<KeyPointCallout title="Why do some setups need extra config?" defaultCollapsed="true">
OpenTelemetry's span exporter uses a background thread. When a server forks worker processes, this thread doesn't copy over correctly, causing spans to get stuck.

**Gunicorn** loads your app in each worker after forking (so the thread starts fresh). With `--preload`, it loads before forking, causing the same issue.

**uWSGI** loads your app before forking by default. Setting `lazy-apps = true` makes it load after forking instead.
</KeyPointCallout>

</details>

## Validate

With your application running, verify traces are being sent to SigNoz:

1. Trigger an action in your app that generates a web request. Hit the endpoint a few times.
2. In SigNoz, open the **Services** tab and click **Refresh**. Your application should appear.
3. Go to the **Traces** tab to see your application's traces.

<details>
<ToggleHeading>

## Troubleshooting

</ToggleHeading>

### Why don't traces appear in SigNoz?

**Check environment variables are set:**

```bash
echo $OTEL_EXPORTER_OTLP_ENDPOINT
echo $OTEL_RESOURCE_ATTRIBUTES
```

**Verify network connectivity:**

```bash
# For SigNoz Cloud
curl -v https://ingest.<region>.signoz.cloud:443/v1/traces
```

**Enable console exporter to verify spans are being created:**

```bash
OTEL_TRACES_EXPORTER=console opentelemetry-instrument <your_run_command>
```

If you see JSON span output in your terminal but traces don't appear in SigNoz, the issue is with export configuration (endpoint, auth, or network). If no output appears, the instrumentation isn't capturing your requests.

### Why do multi-worker servers (Uvicorn, Gunicorn) drop spans?

Application servers that spawn multiple worker processes require special handling because the OpenTelemetry SDK isn't fork-safe.

- **Uvicorn** with `--workers` flag is not supported. Use Gunicorn with Uvicorn workers instead:
  ```bash
  opentelemetry-instrument gunicorn -k uvicorn.workers.UvicornWorker main:app
  ```
- **Hypercorn/Unicorn** are not supported due to fork-safety issues. See the [Hypercorn/Unicorn tab](#framework-instrumentation) for details and workarounds.
- **Gunicorn with `--preload`** or **uWSGI** need extra config. See [Running with Gunicorn or uWSGI](#running-with-gunicorn-or-uwsgi).

### Hot reload breaks instrumentation

Don't run your app in reloader/hot-reload mode. For Flask, avoid `FLASK_ENV=development`. For Django, use `--noreload`. For Uvicorn/FastAPI, don't use `--reload`.

### gRPC installation issues

If `grpcio` installation fails, use the HTTP exporter instead:

```bash
pip install opentelemetry-exporter-otlp-proto-http
```

Then set `OTEL_EXPORTER_OTLP_PROTOCOL=http/protobuf`.

### Database calls not showing in traces

Auto-instrumentation detects and instruments common database libraries. Ensure you've run `opentelemetry-bootstrap --action=install` after installing your database drivers.

**PostgreSQL note**: `psycopg2` is preferred over `psycopg2-binary` for auto-instrumentation. If you must use `psycopg2-binary`, you may need to use manual instrumentation with `Psycopg2Instrumentor().instrument(skip_dep_check=True)`.

Common database instrumentations installed by bootstrap:
- PostgreSQL: `opentelemetry-instrumentation-psycopg2`
- MySQL: `opentelemetry-instrumentation-pymysql` or `opentelemetry-instrumentation-mysql`
- MongoDB: `opentelemetry-instrumentation-pymongo`
- Redis: `opentelemetry-instrumentation-redis`
- SQLAlchemy: `opentelemetry-instrumentation-sqlalchemy`

Check <a href="https://github.com/open-telemetry/opentelemetry-python-contrib/tree/main/instrumentation" target="_blank" rel="noopener noreferrer nofollow">supported versions</a> for compatibility with your library versions.

</details>

<details>
<ToggleHeading>

## Setup OpenTelemetry Collector (Optional)

</ToggleHeading>

### What is the OpenTelemetry Collector?

Think of the OTel Collector as a middleman between your app and SigNoz. Instead of your application sending data directly to SigNoz, it sends everything to the Collector first, which then forwards it along.

### Why use it?

- **Cleaning up data** — Filter out noisy traces you don't care about, or remove sensitive info before it leaves your servers.
- **Keeping your app lightweight** — Let the Collector handle batching, retries, and compression instead of your application code.
- **Adding context automatically** — The Collector can tag your data with useful info like which Kubernetes pod or cloud region it came from.
- **Future flexibility** — Want to send data to multiple backends later? The Collector makes that easy without changing your app.

See [Switch from direct export to Collector](https://signoz.io/docs/opentelemetry-collection-agents/opentelemetry-collector/switch-to-collector/) for step-by-step instructions to convert your setup.

For more details, see [Why use the OpenTelemetry Collector?](https://signoz.io/docs/opentelemetry-collection-agents/opentelemetry-collector/why-to-use-collector/) and the [Collector configuration guide](https://signoz.io/docs/opentelemetry-collection-agents/opentelemetry-collector/configuration/).

</details>

## Next steps

- [Add manual instrumentation](https://signoz.io/docs/instrumentation/python/manual-instrumentation) for custom spans and attributes
- [Send logs from Python](https://signoz.io/docs/userguide/python-logs-auto-instrumentation/) using auto-instrumentation
- [Send metrics from Python](https://signoz.io/docs/metrics-management/send-metrics/applications/opentelemetry-python/) to correlate traces with metrics for better observability
- [Set up alerts](https://signoz.io/docs/setup-alerts-notification/) for your Python application
- [Create dashboards](https://signoz.io/docs/userguide/manage-dashboards/) to visualize metrics

**Sample applications**:
- <a href="https://github.com/SigNoz/sample-django" target="_blank" rel="noopener noreferrer nofollow">Django sample app</a>
- <a href="https://github.com/SigNoz/sample-flask-app" target="_blank" rel="noopener noreferrer nofollow">Flask sample app</a>
- <a href="https://github.com/SigNoz/sample-fastAPI-app" target="_blank" rel="noopener noreferrer nofollow">FastAPI sample app</a>

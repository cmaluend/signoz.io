# GitHub Actions Workflow: Sync Content to Strapi CMS (Using Vercel Env Vars)
# This workflow syncs content changes from specific data folders to Strapi CMS
# Environment variables are fetched from Vercel project settings
# Triggers: On labeled PR, on push to staging/main branches

name: Sync Content to Strapi CMS

on:
  pull_request:
    types: [labeled, synchronize, opened, reopened]
    paths:
      - 'data/**/*.mdx'
      - 'data/**/*.md'
  push:
    branches:
      - test/cms-with-isr  # Change to production branch
      - test/cms-with-isr  # Change to staging branch
    paths:
      - 'data/**/*.mdx'
      - 'data/**/*.md'

env:
  # Array of folders to sync to CMS
  SYNC_FOLDERS: '["faqs"]'  # Add more folders here like - '["faqs", "blogs", "docs"]'
  
  # Vercel Configuration (only these are stored as GitHub Secrets)
  VERCEL_TOKEN: ${{ secrets.VERCEL_TOKEN }}
  VERCEL_PROJECT_ID: ${{ secrets.VERCEL_PROJECT_ID }}
  # VERCEL_ORG_ID: ${{ secrets.VERCEL_ORG_ID }}  # Optional: Required for team projects
  
  # Branch Configuration - change later
  PRODUCTION_BRANCH: 'test/cms-with-isr'
  STAGING_BRANCH: 'test/cms-with-isr'

jobs:
  detect-changes:
    name: Detect Changed Files
    runs-on: ubuntu-latest
    outputs:
      changed_files: ${{ steps.changed-files.outputs.all_changed_files }}
      any_changed: ${{ steps.changed-files.outputs.any_changed }}
      deployment_status: ${{ steps.determine-status.outputs.deployment_status }}
      should_sync: ${{ steps.check-sync.outputs.should_sync }}
    
    steps:
      - name: Checkout Repository
        uses: actions/checkout@v4
        with:
          fetch-depth: 0  # Fetch all history for accurate diff

      - name: Get Changed Files
        id: changed-files
        uses: tj-actions/changed-files@v44
        with:
          files: |
            data/**/*.mdx
            data/**/*.md
          json: true
          escape_json: false

      - name: Check if Sync is Required
        id: check-sync
        run: |
          echo "Checking if sync should run..."
          
          # Check if this is a labeled PR with 'staging' label
          if [[ "${{ github.event_name }}" == "pull_request" ]]; then
            if [[ "${{ contains(github.event.pull_request.labels.*.name, 'staging') }}" == "true" ]]; then
              echo "should_sync=true" >> $GITHUB_OUTPUT
              echo "‚úÖ Sync enabled: PR has 'staging' label"
            else
              echo "should_sync=false" >> $GITHUB_OUTPUT
              echo "‚è≠Ô∏è Sync skipped: PR does not have 'staging' label"
            fi
          else
            # For push events, always sync
            echo "should_sync=true" >> $GITHUB_OUTPUT
            echo "‚úÖ Sync enabled: Push event to branch"
          fi

      - name: Determine Deployment Status
        id: determine-status
        run: |
          # Determine deployment status based on event type and branch
          if [[ "${{ github.event_name }}" == "pull_request" ]]; then
            if [[ "${{ contains(github.event.pull_request.labels.*.name, 'staging') }}" == "true" ]]; then
              echo "deployment_status=staging" >> $GITHUB_OUTPUT
              echo "üì¶ Deployment Status: staging"
            else
              echo "deployment_status=draft" >> $GITHUB_OUTPUT
              echo "üì¶ Deployment Status: draft"
            fi
          elif [[ "${{ github.ref }}" == "refs/heads/${{ env.PRODUCTION_BRANCH }}" ]]; then
            echo "deployment_status=live" >> $GITHUB_OUTPUT
            echo "üì¶ Deployment Status: live"
          elif [[ "${{ github.ref }}" == "refs/heads/${{ env.STAGING_BRANCH }}" ]]; then
            echo "deployment_status=staging" >> $GITHUB_OUTPUT
            echo "üì¶ Deployment Status: staging"
          else
            echo "deployment_status=draft" >> $GITHUB_OUTPUT
            echo "üì¶ Deployment Status: draft"
          fi

      - name: Display Changed Files
        if: steps.changed-files.outputs.any_changed == 'true'
        run: |
          echo "üìù Changed files detected:"
          echo '${{ steps.changed-files.outputs.all_changed_files }}' | jq -r '.[]'

  fetch-vercel-env:
    name: Fetch Vercel Environment Variables
    runs-on: ubuntu-latest
    needs: detect-changes
    if: needs.detect-changes.outputs.any_changed == 'true' && needs.detect-changes.outputs.should_sync == 'true'
    outputs:
      env_vars: ${{ steps.get-env.outputs.env_vars }}
    
    steps:
      - name: Fetch Environment Variables from Vercel
        id: get-env
        run: |
          echo "üîê Fetching environment variables from Vercel..."
          
          # Validate required inputs
          if [ -z "${{ env.VERCEL_TOKEN }}" ] || [ -z "${{ env.VERCEL_PROJECT_ID }}" ]; then
            echo "‚ùå Error: VERCEL_TOKEN and VERCEL_PROJECT_ID are required"
            exit 1
          fi
          
          # Determine which environment to pull based on deployment status
          VERCEL_ENV="production"
          if [[ "${{ needs.detect-changes.outputs.deployment_status }}" == "staging" ]]; then
            VERCEL_ENV="preview"
          elif [[ "${{ needs.detect-changes.outputs.deployment_status }}" == "draft" ]]; then
            VERCEL_ENV="preview"
          fi
          
          echo "üì¶ Fetching environment: $VERCEL_ENV"
          
          # Construct API URL
          if [ -n "${{ env.VERCEL_ORG_ID }}" ]; then
            API_URL="https://api.vercel.com/v9/projects/${{ env.VERCEL_PROJECT_ID }}/env?teamId=${{ env.VERCEL_ORG_ID }}"
          else
            API_URL="https://api.vercel.com/v9/projects/${{ env.VERCEL_PROJECT_ID }}/env"
          fi
          
          # Fetch environment variables from Vercel API
          RESPONSE=$(curl -s -H "Authorization: Bearer ${{ env.VERCEL_TOKEN }}" "$API_URL")
          
          # Check if request was successful
          if echo "$RESPONSE" | jq -e '.error' > /dev/null 2>&1; then
            ERROR_MSG=$(echo "$RESPONSE" | jq -r '.error.message')
            echo "‚ùå Error fetching environment variables: $ERROR_MSG"
            exit 1
          fi
          
          # Extract environment variables for the target environment
          # We need: NEXT_PUBLIC_SIGNOZ_CMS_API_URL, CMS_API_TOKEN, NEXT_PUBLIC_BASE_URL, REVALIDATE_SECRET
          
          echo "üîç Extracting required environment variables..."
          
          NEXT_PUBLIC_SIGNOZ_CMS_API_URL=$(echo "$RESPONSE" | jq -r --arg env "$VERCEL_ENV" \
            '.envs[] | select(.key == "NEXT_PUBLIC_SIGNOZ_CMS_API_URL" and (.target[] | contains($env))) | .value' | head -n 1)
          
          CMS_API_TOKEN=$(echo "$RESPONSE" | jq -r --arg env "$VERCEL_ENV" \
            '.envs[] | select(.key == "CMS_API_TOKEN" and (.target[] | contains($env))) | .value' | head -n 1)
          
          NEXT_PUBLIC_BASE_URL=$(echo "$RESPONSE" | jq -r --arg env "$VERCEL_ENV" \
            '.envs[] | select(.key == "NEXT_PUBLIC_BASE_URL" and (.target[] | contains($env))) | .value' | head -n 1)
          
          REVALIDATE_SECRET=$(echo "$RESPONSE" | jq -r --arg env "$VERCEL_ENV" \
            '.envs[] | select(.key == "REVALIDATE_SECRET" and (.target[] | contains($env))) | .value' | head -n 1)
          
          # Validate that we got all required variables
          MISSING_VARS=()
          [ -z "$NEXT_PUBLIC_SIGNOZ_CMS_API_URL" ] && MISSING_VARS+=("NEXT_PUBLIC_SIGNOZ_CMS_API_URL")
          [ -z "$CMS_API_TOKEN" ] && MISSING_VARS+=("CMS_API_TOKEN")
          [ -z "$NEXT_PUBLIC_BASE_URL" ] && MISSING_VARS+=("NEXT_PUBLIC_BASE_URL")
          [ -z "$REVALIDATE_SECRET" ] && MISSING_VARS+=("REVALIDATE_SECRET")
          
          if [ ${#MISSING_VARS[@]} -gt 0 ]; then
            echo "‚ùå Error: The following required environment variables are not set in Vercel ($VERCEL_ENV environment):"
            printf '   ‚Ä¢ %s\n' "${MISSING_VARS[@]}"
            echo ""
            echo "Please add these variables to your Vercel project settings:"
            echo "https://vercel.com/dashboard ‚Üí Your Project ‚Üí Settings ‚Üí Environment Variables"
            exit 1
          fi
          
          echo "‚úÖ Successfully fetched all required environment variables"
          echo "   ‚Ä¢ NEXT_PUBLIC_SIGNOZ_CMS_API_URL: ${NEXT_PUBLIC_SIGNOZ_CMS_API_URL:0:30}..."
          echo "   ‚Ä¢ CMS_API_TOKEN: ***"
          echo "   ‚Ä¢ NEXT_PUBLIC_BASE_URL: $NEXT_PUBLIC_BASE_URL"
          echo "   ‚Ä¢ REVALIDATE_SECRET: ***"
          
          # Export as JSON for next job (mask sensitive values in output)
          ENV_JSON=$(jq -n \
            --arg strapi_url "$NEXT_PUBLIC_SIGNOZ_CMS_API_URL" \
            --arg strapi_token "$CMS_API_TOKEN" \
            --arg base_url "$NEXT_PUBLIC_BASE_URL" \
            --arg revalidation_key "$REVALIDATE_SECRET" \
            '{
              NEXT_PUBLIC_SIGNOZ_CMS_API_URL: $strapi_url,
              CMS_API_TOKEN: $strapi_token,
              NEXT_PUBLIC_BASE_URL: $base_url,
              REVALIDATE_SECRET: $revalidation_key
            }')
          
          # Use GitHub's masking to hide sensitive values in logs
          echo "::add-mask::$CMS_API_TOKEN"
          echo "::add-mask::$REVALIDATE_SECRET"
          
          echo "env_vars=$ENV_JSON" >> $GITHUB_OUTPUT

  sync-to-cms:
    name: Sync Content to CMS
    runs-on: ubuntu-latest
    needs: [detect-changes, fetch-vercel-env]
    if: needs.detect-changes.outputs.any_changed == 'true' && needs.detect-changes.outputs.should_sync == 'true'
    
    steps:
      - name: Checkout Repository
        uses: actions/checkout@v4
        with:
          fetch-depth: 2  # Need previous commit for accurate change detection

      - name: Setup Node.js
        uses: actions/setup-node@v4
        with:
          node-version: '20'
          cache: 'npm'

      - name: Install Dependencies
        run: |
          npm install --no-save \
            gray-matter \
            axios \
            js-yaml

      - name: Sync Content to Strapi
        id: sync
        env:
          CHANGED_FILES: ${{ needs.detect-changes.outputs.changed_files }}
          DEPLOYMENT_STATUS: ${{ needs.detect-changes.outputs.deployment_status }}
          ENV_VARS: ${{ needs.fetch-vercel-env.outputs.env_vars }}
        run: |
          node << 'EOF'
          const fs = require('fs');
          const path = require('path');
          const matter = require('gray-matter');
          const axios = require('axios');
          
          // Parse environment variables from Vercel
          const ENV_VARS = JSON.parse(process.env.ENV_VARS);
          const NEXT_PUBLIC_SIGNOZ_CMS_API_URL = ENV_VARS.NEXT_PUBLIC_SIGNOZ_CMS_API_URL;
          const CMS_API_TOKEN = ENV_VARS.CMS_API_TOKEN;
          
          // Configuration
          const SYNC_FOLDERS = JSON.parse(process.env.SYNC_FOLDERS);
          const DEPLOYMENT_STATUS = process.env.DEPLOYMENT_STATUS;
          const CHANGED_FILES = JSON.parse(process.env.CHANGED_FILES);
          
          // Strapi Collection Type Schemas
          const COLLECTION_SCHEMAS = {
            faqs: {
              apiPath: 'api::faq.faq',
              endpoint: 'faqs',
              fields: ['title', 'description', 'date', 'path', 'content', 'deployment_status']
            }
            // Add more collection schemas here as needed
          };
          
          // Helper: Extract folder name from file path
          function getFolderName(filePath) {
            const parts = filePath.split('/');
            if (parts[0] === 'data' && parts.length > 1) {
              return parts[1];
            }
            return null;
          }
          
          // Helper: Generate path field from file path
          function generatePathField(filePath, folderName) {
            const parts = filePath.split('/');
            const folderIndex = parts.indexOf(folderName);
            if (folderIndex === -1) return null;
            
            const pathParts = parts.slice(folderIndex + 1);
            const fileName = pathParts[pathParts.length - 1];
            const fileNameWithoutExt = fileName.replace(/\.(mdx?|md)$/, '');
            
            pathParts[pathParts.length - 1] = fileNameWithoutExt;
            return '/' + pathParts.join('/');
          }
          
          // Helper: Parse MDX file
          function parseMDXFile(filePath) {
            try {
              const fileContent = fs.readFileSync(filePath, 'utf8');
              const { data: frontmatter, content } = matter(fileContent);
              return { frontmatter, content };
            } catch (error) {
              throw new Error(`Failed to parse file ${filePath}: ${error.message}`);
            }
          }
          
          // Helper: Map MDX data to Strapi schema
          function mapToStrapiSchema(folderName, frontmatter, content, pathField) {
            const schema = COLLECTION_SCHEMAS[folderName];
            if (!schema) {
              throw new Error(`No schema defined for folder: ${folderName}`);
            }
            
            const data = {
              path: pathField,
              content: content,
              deployment_status: DEPLOYMENT_STATUS,
              ...frontmatter
            };
            
            const missingFields = schema.fields.filter(field => 
              field !== 'deployment_status' && !(field in data)
            );
            
            if (missingFields.length > 0) {
              console.warn(`‚ö†Ô∏è Missing fields in ${pathField}: ${missingFields.join(', ')}`);
            }
            
            return data;
          }
          
          // Helper: Check if file exists in Strapi by path
          async function findEntryByPath(folderName, pathField) {
            const schema = COLLECTION_SCHEMAS[folderName];
            try {
              const response = await axios.get(
                `${NEXT_PUBLIC_SIGNOZ_CMS_API_URL}/api/${schema.endpoint}`,
                {
                  params: {
                    filters: { path: { $eq: pathField } },
                    pagination: { limit: 1 }
                  },
                  headers: {
                    'Authorization': `Bearer ${CMS_API_TOKEN}`,
                    'Content-Type': 'application/json'
                  }
                }
              );
              
              if (response.data.data && response.data.data.length > 0) {
                return response.data.data[0];
              }
              return null;
            } catch (error) {
              throw new Error(`Failed to find entry by path: ${error.message}`);
            }
          }
          
          // Helper: Create entry in Strapi
          async function createEntry(folderName, data) {
            const schema = COLLECTION_SCHEMAS[folderName];
            try {
              const response = await axios.post(
                `${NEXT_PUBLIC_SIGNOZ_CMS_API_URL}/api/${schema.endpoint}`,
                { data },
                {
                  headers: {
                    'Authorization': `Bearer ${CMS_API_TOKEN}`,
                    'Content-Type': 'application/json'
                  }
                }
              );
              return response.data;
            } catch (error) {
              const errorMsg = error.response?.data?.error?.message || error.message;
              throw new Error(`Failed to create entry: ${errorMsg}`);
            }
          }
          
          // Helper: Update entry in Strapi
          async function updateEntry(folderName, entryId, data) {
            const schema = COLLECTION_SCHEMAS[folderName];
            try {
              const response = await axios.put(
                `${NEXT_PUBLIC_SIGNOZ_CMS_API_URL}/api/${schema.endpoint}/${entryId}`,
                { data },
                {
                  headers: {
                    'Authorization': `Bearer ${CMS_API_TOKEN}`,
                    'Content-Type': 'application/json'
                  }
                }
              );
              return response.data;
            } catch (error) {
              const errorMsg = error.response?.data?.error?.message || error.message;
              throw new Error(`Failed to update entry: ${errorMsg}`);
            }
          }
          
          // Helper: Delete entry in Strapi
          async function deleteEntry(folderName, entryId) {
            const schema = COLLECTION_SCHEMAS[folderName];
            try {
              const response = await axios.delete(
                `${NEXT_PUBLIC_SIGNOZ_CMS_API_URL}/api/${schema.endpoint}/${entryId}`,
                {
                  headers: {
                    'Authorization': `Bearer ${CMS_API_TOKEN}`,
                    'Content-Type': 'application/json'
                  }
                }
              );
              return response.data;
            } catch (error) {
              const errorMsg = error.response?.data?.error?.message || error.message;
              throw new Error(`Failed to delete entry: ${errorMsg}`);
            }
          }
          
          // Helper: Detect operation type
          function detectOperationType(filePath) {
            if (!fs.existsSync(filePath)) {
              return 'delete';
            }
            return 'create_or_update';
          }
          
          // Main sync logic
          async function syncToStrapi() {
            console.log('üöÄ Starting sync to Strapi CMS...\n');
            console.log(`üì¶ Deployment Status: ${DEPLOYMENT_STATUS}\n`);
            
            const results = {
              created: [],
              updated: [],
              deleted: [],
              skipped: [],
              errors: []
            };
            
            for (const filePath of CHANGED_FILES) {
              console.log(`\nüìÑ Processing: ${filePath}`);
              
              try {
                const folderName = getFolderName(filePath);
                
                if (!folderName || !SYNC_FOLDERS.includes(folderName)) {
                  console.log(`‚è≠Ô∏è Skipped: Folder '${folderName}' not in sync list`);
                  results.skipped.push(filePath);
                  continue;
                }
                
                const pathField = generatePathField(filePath, folderName);
                if (!pathField) {
                  throw new Error('Could not generate path field');
                }
                
                const operationType = detectOperationType(filePath);
                
                if (operationType === 'delete') {
                  console.log(`üóëÔ∏è Deleting from CMS: ${pathField}`);
                  const existingEntry = await findEntryByPath(folderName, pathField);
                  
                  if (existingEntry) {
                    await deleteEntry(folderName, existingEntry.id);
                    console.log(`‚úÖ Deleted successfully`);
                    results.deleted.push(filePath);
                  } else {
                    console.log(`‚ö†Ô∏è Entry not found in CMS, skipping deletion`);
                    results.skipped.push(filePath);
                  }
                } else {
                  const { frontmatter, content } = parseMDXFile(filePath);
                  const strapiData = mapToStrapiSchema(folderName, frontmatter, content, pathField);
                  
                  const existingEntry = await findEntryByPath(folderName, pathField);
                  
                  if (existingEntry) {
                    console.log(`üîÑ Updating in CMS: ${pathField}`);
                    await updateEntry(folderName, existingEntry.id, strapiData);
                    console.log(`‚úÖ Updated successfully`);
                    results.updated.push(filePath);
                  } else {
                    console.log(`‚ûï Creating in CMS: ${pathField}`);
                    await createEntry(folderName, strapiData);
                    console.log(`‚úÖ Created successfully`);
                    results.created.push(filePath);
                  }
                }
              } catch (error) {
                console.error(`‚ùå Error processing ${filePath}: ${error.message}`);
                results.errors.push({ file: filePath, error: error.message });
              }
            }
            
            // Print summary
            console.log('\n' + '='.repeat(60));
            console.log('üìä SYNC SUMMARY');
            console.log('='.repeat(60));
            console.log(`‚úÖ Created: ${results.created.length}`);
            console.log(`üîÑ Updated: ${results.updated.length}`);
            console.log(`üóëÔ∏è Deleted: ${results.deleted.length}`);
            console.log(`‚è≠Ô∏è Skipped: ${results.skipped.length}`);
            console.log(`‚ùå Errors: ${results.errors.length}`);
            console.log('='.repeat(60) + '\n');
            
            if (results.errors.length > 0) {
              console.error('\n‚ùå SYNC FAILED - The following errors occurred:\n');
              results.errors.forEach(({ file, error }) => {
                console.error(`  ‚Ä¢ ${file}: ${error}`);
              });
              process.exit(1);
            }
            
            return results;
          }
          
          // Validate environment variables
          if (!NEXT_PUBLIC_SIGNOZ_CMS_API_URL || !CMS_API_TOKEN) {
            console.error('‚ùå ERROR: Missing required environment variables from Vercel');
            console.error('   Required: NEXT_PUBLIC_SIGNOZ_CMS_API_URL, CMS_API_TOKEN');
            process.exit(1);
          }
          
          // Run sync
          syncToStrapi()
            .then(() => {
              console.log('‚úÖ Sync completed successfully!');
            })
            .catch((error) => {
              console.error('‚ùå SYNC FAILED:', error.message);
              process.exit(1);
            });
          EOF

      - name: Trigger Revalidation
        if: success()
        env:
          ENV_VARS: ${{ needs.fetch-vercel-env.outputs.env_vars }}
        run: |
          echo "üîÑ Triggering ISR revalidation..."
          
          # Parse environment variables
          NEXT_PUBLIC_BASE_URL=$(echo '${{ needs.fetch-vercel-env.outputs.env_vars }}' | jq -r '.NEXT_PUBLIC_BASE_URL')
          REVALIDATE_SECRET=$(echo '${{ needs.fetch-vercel-env.outputs.env_vars }}' | jq -r '.REVALIDATE_SECRET')
          
          RESPONSE=$(curl -s -w "\n%{http_code}" --location "$NEXT_PUBLIC_BASE_URL/api/revalidate" \
            --header 'Content-Type: application/json' \
            --data "{
              \"revalidateAll\": true,
              \"clearCache\": true,
              \"secret\": \"$REVALIDATE_SECRET\"
            }")
          
          HTTP_CODE=$(echo "$RESPONSE" | tail -n1)
          BODY=$(echo "$RESPONSE" | head -n-1)
          
          if [ "$HTTP_CODE" -eq 200 ]; then
            echo "‚úÖ Revalidation successful!"
            echo "Response: $BODY"
          else
            echo "‚ùå Revalidation failed with HTTP $HTTP_CODE"
            echo "Response: $BODY"
            exit 1
          fi

      - name: Update PR Comment
        if: github.event_name == 'pull_request'
        uses: actions/github-script@v7
        with:
          script: |
            const status = '${{ job.status }}';
            const deploymentStatus = '${{ needs.detect-changes.outputs.deployment_status }}';
            
            const body = status === 'success' 
              ? `‚úÖ **CMS Sync Successful**\n\nContent has been synced to Strapi CMS with deployment status: \`${deploymentStatus}\`\n\n_Environment variables loaded from Vercel project settings_`
              : `‚ùå **CMS Sync Failed**\n\nPlease check the workflow logs for details.`;
            
            github.rest.issues.createComment({
              issue_number: context.issue.number,
              owner: context.repo.owner,
              repo: context.repo.repo,
              body: body
            });

  report-status:
    name: Report Status
    runs-on: ubuntu-latest
    needs: [detect-changes, fetch-vercel-env, sync-to-cms]
    if: always()
    
    steps:
      - name: Report Success
        if: needs.sync-to-cms.result == 'success'
        run: |
          echo "‚úÖ Workflow completed successfully!"
          echo "Deployment Status: ${{ needs.detect-changes.outputs.deployment_status }}"
          echo "Environment variables were loaded from Vercel"

      - name: Report Failure
        if: needs.sync-to-cms.result == 'failure' || needs.fetch-vercel-env.result == 'failure'
        run: |
          echo "‚ùå Workflow failed!"
          if [[ "${{ needs.fetch-vercel-env.result }}" == "failure" ]]; then
            echo "Failed to fetch environment variables from Vercel"
            echo "Please ensure:"
            echo "  1. VERCEL_TOKEN is set in GitHub Secrets"
            echo "  2. VERCEL_PROJECT_ID is set in GitHub Secrets"
            echo "  3. Required env vars exist in Vercel project settings"
          fi
          echo "Please check the logs above for detailed error messages."
          exit 1

      - name: Report Skipped
        if: needs.detect-changes.outputs.should_sync != 'true' || needs.detect-changes.outputs.any_changed != 'true'
        run: |
          echo "‚è≠Ô∏è Sync was skipped."
          if [[ "${{ needs.detect-changes.outputs.any_changed }}" != "true" ]]; then
            echo "Reason: No content files changed"
          else
            echo "Reason: PR does not have 'staging' label"
          fi
